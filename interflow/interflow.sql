/*
Navicat MySQL Data Transfer

Source Server         : LM
Source Server Version : 50513
Source Host           : localhost:3306
Source Database       : interflow

Target Server Type    : MYSQL
Target Server Version : 50513
File Encoding         : 65001

Date: 2018-06-07 18:22:25
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for `answer`
-- ----------------------------
DROP TABLE IF EXISTS `answer`;
CREATE TABLE `answer` (
  `aid` varchar(50) NOT NULL,
  `content` varchar(1000) DEFAULT NULL,
  `supportCnt` int(11) DEFAULT '0',
  `opposeCnt` int(11) DEFAULT '0',
  `answerTo` varchar(50) DEFAULT NULL,
  `time` varchar(50) DEFAULT NULL,
  `uid` varchar(50) DEFAULT NULL,
  `accept` int(11) NOT NULL DEFAULT '0' COMMENT '是否采纳',
  `praise` int(11) NOT NULL DEFAULT '0',
  `username` varchar(20) DEFAULT NULL,
  `qid` varchar(50) DEFAULT NULL,
  `toid` varchar(50) DEFAULT NULL,
  `questiontitle` varchar(50) DEFAULT NULL,
  `userface` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`aid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of answer
-- ----------------------------

-- ----------------------------
-- Table structure for `attention`
-- ----------------------------
DROP TABLE IF EXISTS `attention`;
CREATE TABLE `attention` (
  `id` varchar(50) NOT NULL,
  `uid` varchar(50) NOT NULL,
  `aid` varchar(50) NOT NULL,
  `date` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of attention
-- ----------------------------

-- ----------------------------
-- Table structure for `board`
-- ----------------------------
DROP TABLE IF EXISTS `board`;
CREATE TABLE `board` (
  `bid` varchar(50) NOT NULL,
  `title` varchar(100) DEFAULT NULL,
  `content` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`bid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of board
-- ----------------------------

-- ----------------------------
-- Table structure for `chatmsg`
-- ----------------------------
DROP TABLE IF EXISTS `chatmsg`;
CREATE TABLE `chatmsg` (
  `id` varchar(255) NOT NULL,
  `fromid` varchar(255) NOT NULL,
  `toid` varchar(255) NOT NULL,
  `content` varchar(255) NOT NULL,
  `createtime` datetime DEFAULT NULL,
  `groupid` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of chatmsg
-- ----------------------------

-- ----------------------------
-- Table structure for `forum`
-- ----------------------------
DROP TABLE IF EXISTS `forum`;
CREATE TABLE `forum` (
  `fid` varchar(50) NOT NULL,
  `title` varchar(255) DEFAULT NULL,
  `content` text,
  `type` int(11) DEFAULT NULL,
  `uid` varchar(50) DEFAULT NULL,
  `status` int(11) DEFAULT NULL,
  `time` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`fid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of forum
-- ----------------------------
INSERT INTO `forum` VALUES ('2d869735-4eeb-4093-aba3-6442840a59af', 'JAVA开发', 'java技术交流', '1', 'cd2e66c1-fe69-4844-92ff-38ecbfb88e0b', '1', '2018-05-16 10:11:55');
INSERT INTO `forum` VALUES ('37be2631-5180-4bde-bc6a-f0e98201173c', 'happy', 'fine', '2', '99ef5612-f650-460d-9b0f-13c81f8e5cb2', '1', '2018-05-16 11:29:29');
INSERT INTO `forum` VALUES ('39c84611-d107-4da0-964a-7183cc5e1024', '大学生活', '分享你的大学生活', '2', 'cd2e66c1-fe69-4844-92ff-38ecbfb88e0b', '1', '2018-05-16 10:09:13');
INSERT INTO `forum` VALUES ('478f5098-87fa-4278-ab29-a9afa1682ea3', 'java', 'java技术交流', '1', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '1', '2018-05-21 12:45:33');
INSERT INTO `forum` VALUES ('6ddee1d8-8957-41c7-8554-21a0104c7690', 'C++', 'C++讨论学习', '1', '99ef5612-f650-460d-9b0f-13c81f8e5cb2', '1', '2018-05-16 10:26:42');
INSERT INTO `forum` VALUES ('7850ff1f-79f9-4a1d-8cae-ccc61c0ebf99', '大学', '123', '2', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '2', '2018-05-29 20:24:02');
INSERT INTO `forum` VALUES ('e88258ae-e7f5-4e49-819d-c73bd3d47004', 'Python开发', 'python交流', '1', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '0', '2018-05-16 15:38:14');
INSERT INTO `forum` VALUES ('eabe1abf-e554-4c35-baef-8df1131eb297', '创新创业大赛', '创新创业比赛讨论', '1', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '1', '2018-06-07 16:46:16');

-- ----------------------------
-- Table structure for `friends`
-- ----------------------------
DROP TABLE IF EXISTS `friends`;
CREATE TABLE `friends` (
  `id` varchar(50) NOT NULL,
  `userid` varchar(50) DEFAULT NULL,
  `friendid` varchar(50) DEFAULT NULL,
  `status` int(11) DEFAULT NULL,
  `date` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of friends
-- ----------------------------
INSERT INTO `friends` VALUES ('89761c2c-7297-49e6-af5f-68d499e140a7', '99ef5612-f650-460d-9b0f-13c81f8e5cb2', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '1', '2018-06-06 10:48:59');
INSERT INTO `friends` VALUES ('c9894e4b-2cee-4418-8e7c-b0476195bc17', '9d2478de-32fa-40f2-9c97-0733265d5ea2', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '1', '2018-06-06 10:45:48');

-- ----------------------------
-- Table structure for `group`
-- ----------------------------
DROP TABLE IF EXISTS `group`;
CREATE TABLE `group` (
  `id` varchar(255) NOT NULL,
  `groupname` varchar(50) NOT NULL,
  `abstract` varchar(255) NOT NULL,
  `createtime` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of group
-- ----------------------------

-- ----------------------------
-- Table structure for `group_user`
-- ----------------------------
DROP TABLE IF EXISTS `group_user`;
CREATE TABLE `group_user` (
  `id` varchar(255) NOT NULL,
  `userid` varchar(255) DEFAULT NULL,
  `groupid` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of group_user
-- ----------------------------

-- ----------------------------
-- Table structure for `message`
-- ----------------------------
DROP TABLE IF EXISTS `message`;
CREATE TABLE `message` (
  `id` varchar(50) NOT NULL,
  `time` varchar(50) NOT NULL,
  `content` text NOT NULL,
  `href` varchar(1000) DEFAULT NULL,
  `fromid` varchar(50) NOT NULL,
  `toid` varchar(50) DEFAULT NULL,
  `fromstatus` int(4) NOT NULL DEFAULT '0' COMMENT '来源方状态',
  `tostatus` int(4) NOT NULL DEFAULT '0' COMMENT '到达方状态',
  `type` int(11) DEFAULT '0' COMMENT '类型',
  `fromname` varchar(50) DEFAULT NULL COMMENT '来源方名称',
  `toname` varchar(50) DEFAULT NULL COMMENT '到达方名字',
  `readstatus` int(4) NOT NULL DEFAULT '0',
  `title` varchar(100) DEFAULT NULL,
  `fid` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of message
-- ----------------------------

-- ----------------------------
-- Table structure for `news`
-- ----------------------------
DROP TABLE IF EXISTS `news`;
CREATE TABLE `news` (
  `nid` varchar(50) NOT NULL,
  `title` varchar(50) DEFAULT NULL,
  `date` varchar(50) DEFAULT NULL,
  `n_id` varchar(50) DEFAULT NULL,
  `type` int(11) DEFAULT '0',
  `url` varchar(255) DEFAULT NULL,
  `source` varchar(50) DEFAULT NULL,
  `imgurl` varchar(255) DEFAULT NULL,
  `readnum` int(11) DEFAULT '0',
  PRIMARY KEY (`nid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of news
-- ----------------------------
INSERT INTO `news` VALUES ('a087052a-6a3b-11e8-8580-000c29753dbb', '拼多多回应涉黄涉暴:欢迎各界举报店铺违规行为', '2018-06-07 17:42:01', 'a087052a-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493362.html', '中华网', 'http://sc1.hao123img.com/fetch_xk/0b23811b0a06185024b6aea4c70202dc', '678');
INSERT INTO `news` VALUES ('a08c7316-6a3b-11e8-8580-000c29753dbb', '网传河南一高考生证件锁口袋撕衣赶考，考点辟谣：着装不符', '2018-06-07 17:42:02', 'a08c7316-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493319.html', '中华网', 'http://sc0.hao123img.com/fetch_xk/5af776cf3eb7cd92496981cf5043bf61', '611');
INSERT INTO `news` VALUES ('a08e5b86-6a3b-11e8-8580-000c29753dbb', '国产航母最缺的人才，培养一名要30亿，5年只有24人合格', '2018-06-07 17:41:08', 'a08e5b86-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673881_1.html', '米尔网', 'http://sc2.hao123img.com/fetch_xk/3a47404c2afc84ead8012ad6dcf438a5', '611');
INSERT INTO `news` VALUES ('a08f5c3e-6a3b-11e8-8580-000c29753dbb', '2018年高考开考 首批“00后”走进考场', '2018-06-07 17:42:02', 'a08f5c3e-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493340.html', '中华网', 'http://sc1.hao123img.com/fetch_xk/3ae6178ad6309c68402abd6fcafbb523', '149');
INSERT INTO `news` VALUES ('a09025ce-6a3b-11e8-8580-000c29753dbb', '高考生拉链拉不开撕衣赶考？考点辟谣：着装不符', '2018-06-07 17:42:04', 'a09025ce-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493194.html', '中华网', 'http://sc3.hao123img.com/fetch_xk/a1a6598b0427e2d9f61511b8909d0258', '209');
INSERT INTO `news` VALUES ('a0911ef2-6a3b-11e8-8580-000c29753dbb', '劳碌奔波了那么久，你的身体还好吗？', '2018-06-07 17:40:01', 'a0911ef2-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172848240.html?qid=01333', '掌上体检1', 'http://sc4.hao123img.com/fetch_xk/a8f8bef382f094bcaee47cda8fa38786', '929');
INSERT INTO `news` VALUES ('a0934a88-6a3b-11e8-8580-000c29753dbb', '车主们注意了！5月这些问题车都被召回！', '2018-06-07 17:39:59', 'a0934a88-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172848256.html?qid=01333', '汽车保养诀', 'http://sc3.hao123img.com/fetch_xk/ed72da7c5bb03ad591f49058f1029420', '394');
INSERT INTO `news` VALUES ('a096fdf4-6a3b-11e8-8580-000c29753dbb', '摩拜员工坠楼 摩拜:愿意为家属全力提供协助', '2018-06-07 17:42:03', 'a096fdf4-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493227.html', '中华网', 'http://sc0.hao123img.com/fetch_xk/fab2beff6dc1caf1d3464d98cf2c2144', '552');
INSERT INTO `news` VALUES ('a09c25cc-6a3b-11e8-8580-000c29753dbb', '当年高考红极一时的0分考生 现在都怎么样了?', '2018-06-07 17:42:03', 'a09c25cc-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493221.html', '中华网', 'http://sc3.hao123img.com/fetch_xk/b7bfdc8194c7895da5ac13c3fd4bcadd', '352');
INSERT INTO `news` VALUES ('a09cc11c-6a3b-11e8-8580-000c29753dbb', '美太空部队计划被抛弃，竟是俄罗斯这新武器没法设防', '2018-06-07 17:41:09', 'a09cc11c-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673887_1.html', '米尔网', 'http://sc4.hao123img.com/fetch_xk/90dabc63211a2116b192fc186786c2a2', '8');
INSERT INTO `news` VALUES ('a09d3b38-6a3b-11e8-8580-000c29753dbb', '帕萨特最新行情价 六月买车最优惠 厂家直销不用找熟人 直击底价', '2018-06-07 17:40:04', 'a09d3b38-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172848008.html?qid=01333', '汽车保养诀', 'http://sc4.hao123img.com/fetch_xk/c1c5b1336084accc4adb30c2c5ec896e', '397');
INSERT INTO `news` VALUES ('a09dca08-6a3b-11e8-8580-000c29753dbb', '微软近500亿收购GitHub，开发者们为何这么值钱？', '2018-06-07 17:40:08', 'a09dca08-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172847528.html?qid=01333', '科技圈子', 'http://sc3.hao123img.com/fetch_xk/4a3c9bd935ad5d43a9bf748d50f3c516', '336');
INSERT INTO `news` VALUES ('a09e7ab6-6a3b-11e8-8580-000c29753dbb', '曾现UFO，中国神秘“51区”露真面目：可容纳450架战机', '2018-06-07 17:41:09', 'a09e7ab6-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673889_1.html', '米尔网', 'http://sc3.hao123img.com/fetch_xk/bb6e49dc8a921c0760c3605799d27545', '1000');
INSERT INTO `news` VALUES ('a09f01d4-6a3b-11e8-8580-000c29753dbb', '黄子韬黑白穿搭大秀潮范 造型干练尽显帅气活力', '2018-06-07 17:40:03', 'a09f01d4-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172848095.html?qid=01333', '新浪娱乐', 'http://sc0.hao123img.com/fetch_xk/9bc715bf9c8817014761a5c83c066dfb', '286');
INSERT INTO `news` VALUES ('a09f6fa2-6a3b-11e8-8580-000c29753dbb', '全球最大战略轰炸机即将服役，当年差点打包卖给中国10架', '2018-06-07 17:41:27', 'a09f6fa2-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673931_1.html', '米尔网', 'http://sc3.hao123img.com/fetch_xk/5aaa8a1df7a6f87479a4f67945b23080', '140');
INSERT INTO `news` VALUES ('a09fd6d6-6a3b-11e8-8580-000c29753dbb', '印度航母质量太差，把美国专家吓一跳：看着像游艇', '2018-06-07 17:41:09', 'a09fd6d6-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673891_1.html', '米尔网', 'http://sc0.hao123img.com/fetch_xk/cb514662367bafaa9df6b3576d210456', '935');
INSERT INTO `news` VALUES ('a0a063f8-6a3b-11e8-8580-000c29753dbb', '猪流感可传染给狗 对人类的潜在威胁不容忽视', '2018-06-07 17:42:02', 'a0a063f8-6a3b-11e8-8580-000c29753dbb', '0', 'http://toutiao.china.com/shsy/gundong4/13000238/20180607/32493290.html', '中华网', 'http://sc0.hao123img.com/fetch_xk/fcd6f863a5660a8ebda975ab0758113d', '862');
INSERT INTO `news` VALUES ('a0a86bac-6a3b-11e8-8580-000c29753dbb', '兰云科技立志成为安全服务运营商', '2018-06-07 17:40:06', 'a0a86bac-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172847733.html?qid=01333', '科技传播站', 'http://sc3.hao123img.com/fetch_xk/6e79a1a034120790a59ca60bba99fe30', '276');
INSERT INTO `news` VALUES ('a0a985a0-6a3b-11e8-8580-000c29753dbb', '幽默笑话；我同桌就举手说：老师我想上厕所……', '2018-06-07 17:40:07', 'a0a985a0-6a3b-11e8-8580-000c29753dbb', '0', 'https://mini.eastday.com/a/180607172847636.html?qid=01333', '笑哭了', 'http://sc0.hao123img.com/fetch_xk/ca3892e9e7bdc33a4a44a1da0f67b3dd', '405');
INSERT INTO `news` VALUES ('a0aa0b7e-6a3b-11e8-8580-000c29753dbb', '深夜，辽宁舰甲板一声响，困扰中国多年问题被解决，这回放心了', '2018-06-07 17:41:07', 'a0aa0b7e-6a3b-11e8-8580-000c29753dbb', '0', 'http://bbs.miercn.com/hao123bottom/201806/thread_1673877_1.html', '米尔网', 'http://sc0.hao123img.com/fetch_xk/d4074477d5ec1c0c111c74ab4e7ef66c', '325');
INSERT INTO `news` VALUES ('a3238b8c-6a3b-11e8-8580-000c29753dbb', '阿里巴巴为什么不用 ZooKeeper 做服务发现？', '2018-06-07 18:14:58', '6a13231b-2f5f-4763-bcfd-6330af9d4d7b', '1', 'https://juejin.im/entry/5b18c3e65188254fbb75689b', '掘金', null, '0');
INSERT INTO `news` VALUES ('a71384ae-6a3b-11e8-8580-000c29753dbb', 'Java集合之HashMap源码解析', '2018-06-07 18:14:58', '2220941f-1551-4920-8204-d803a2eb083c', '1', 'https://juejin.im/entry/5b18cbaf6fb9a01e2c697ddf', '掘金', null, '0');
INSERT INTO `news` VALUES ('a7ab6ada-6a3b-11e8-8580-000c29753dbb', 'Laravel 程序架构设计思路：使用动作类', '2018-06-07 18:14:58', 'feef13d6-5ed3-4012-8f49-deec3133114d', '1', 'https://juejin.im/entry/5b189e1e6fb9a01e6f561402', '掘金', null, '0');
INSERT INTO `news` VALUES ('a8f6f026-6a3b-11e8-8580-000c29753dbb', 'nginx中location详解', '2018-06-07 18:14:58', '311e9c37-e064-4db9-b2e3-07eb68cd1d0e', '1', 'https://juejin.im/entry/5b187254f265da6e3a5ad55a', '掘金', null, '0');
INSERT INTO `news` VALUES ('a958f5a0-6a3b-11e8-8580-000c29753dbb', '详解Spring Retry实现原理', '2018-06-07 18:14:58', '67ad19a6-0a81-458a-b1a8-3d60698044ff', '1', 'https://juejin.im/post/5b18a28d6fb9a01e4072b189', '掘金', null, '0');
INSERT INTO `news` VALUES ('abd6cdf2-6a3b-11e8-8580-000c29753dbb', '从单一架构到分布式交易架构，网易严选的成功实践', '2018-06-07 18:14:58', '08226d13-a1db-49eb-ba0b-4109f1e98732', '1', 'https://juejin.im/entry/5b17592df265da6e123d9cbf', '掘金', null, '0');
INSERT INTO `news` VALUES ('ad418902-6a3b-11e8-8580-000c29753dbb', 'Netty源码分析——Reactor的task', '2018-06-07 18:14:58', 'fe9ff561-c93b-4cf0-a31e-d7f28ec4dfde', '1', 'https://juejin.im/entry/5b18d311e51d45069562a095', '掘金', null, '0');
INSERT INTO `news` VALUES ('add37d76-6a3b-11e8-8580-000c29753dbb', '关于Golang过滤敏感信息的正确姿势', '2018-06-07 18:14:58', '3156d6fe-c74c-430f-98fa-d6b5ee6ffd13', '1', 'https://juejin.im/entry/5b18a3a0f265da6e1c4adf80', '掘金', null, '0');
INSERT INTO `news` VALUES ('af3b8c94-6a3b-11e8-8580-000c29753dbb', '唯品会 Java 核心项目 VJTools 开源', '2018-06-07 18:14:58', 'd9e54091-7af9-448b-b3b7-f39a85511c25', '1', 'https://juejin.im/entry/5b1733ea5188257d9b79cf63', '掘金', null, '0');

-- ----------------------------
-- Table structure for `notice`
-- ----------------------------
DROP TABLE IF EXISTS `notice`;
CREATE TABLE `notice` (
  `id` varchar(50) NOT NULL,
  `content` text,
  `time` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of notice
-- ----------------------------
INSERT INTO `notice` VALUES ('5c5974c5-cc65-4958-8b93-356bae5bd03b', '本系统在更新状态，请见谅！', '2018-05-06 15:42:08');
INSERT INTO `notice` VALUES ('d2cfbab8-c5ff-4c4b-b7b6-9a878306e407', '欢迎大家来本网站寻找好基友<img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/42.gif\" alt=\"\" border=\"0\" /><img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/42.gif\" alt=\"\" border=\"0\" /><img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/44.gif\" alt=\"\" border=\"0\" /><img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/82.gif\" alt=\"\" border=\"0\" /><br />', '2018-05-14 10:29:01');

-- ----------------------------
-- Table structure for `nsnews`
-- ----------------------------
DROP TABLE IF EXISTS `nsnews`;
CREATE TABLE `nsnews` (
  `nsid` varchar(50) NOT NULL,
  `title` varchar(50) DEFAULT NULL,
  `content` mediumtext,
  `autherurl` varchar(50) DEFAULT NULL,
  `date` varchar(0) DEFAULT NULL,
  `views` int(11) DEFAULT NULL,
  `source` varchar(50) DEFAULT NULL,
  `nid` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`nsid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of nsnews
-- ----------------------------
INSERT INTO `nsnews` VALUES ('08226d13-a1db-49eb-ba0b-4109f1e98732', '从单一架构到分布式交易架构，网易严选的成功实践', '\n    \n                     \n         作者｜马超 \n         编辑｜薛梁 \n         过去两年严选提出并设计了统一售后模型、最大可退金额、和多级退款引擎等概念，抽象出了销退支持、上门取件、极速退款、售后风控等通用能力，经过几次架构演变，有效的降低了业务逻辑耦合和复杂度，可以做到上层业务的快速搭建和服务接入。 \n        作为电商产品，交易在严选的业务中承担着重要的角色。随着业务的不断发展，交易场景的定制化和差异化开始凸显，同时第三方支付合作方的接入也越来越多，如何在保证交易服务安全稳定的同时做到良好的扩展和弹性是近一年严选在分布式交易架构中思考和实践的重点。\n        很荣幸，InfoQ 采访了网易严选技术经理，ArchSummit 全球架构师技术峰会讲师 马超，从核心数据模型迭代、服务架构演变等方面介绍严选商城在交易环节的分布式技术架构实践。（马超也会在 7 月深圳 ArchSummit 峰会上分享《大道至简 - 严选售后服务架构演变实践》话题）\n       \n        （为便于完整展示严选技术迭代历程，文章将对话在不改变原意的基础上进行第一人称改写）\n         严选分布式交易架构演变简史 \n        严选把交易环节定义为能够促成买家和卖家达成契约的动态过程，而不是简单的把交易和支付直接画上等号。在大多数电商领域，除了货到付款等特殊场景，契约一般都以支付成功的订单形式达成，因此交易架构需要能够很好的支持电商最核心的下单和支付环节。\n        初期刀耕火种阶段，严选商城业务量小，商品数量少且差异小，用户从购物车到下单再到支付的交易模式相对单一。 于是在结算页面生成订单的同时，数据库中冗余了一条支付相关的记录，使支付的金额和订单结算金额保持一致。然后以此为中介通过一个简单的支付服务来对接微信、支付宝、网易支付三大支付机构，引导用户在客户端完成订单支付，最终再把支付记录的状态同步到订单中去。整个架构简单直接，运转起来也非常高效。\n        早期刮骨疗伤阶段，随着业务发展，严选交易场景开始出现多样化和差异化。 最开始是在支付环节，比如联合登录帐号体系的建立带来了更多第三方支付机构的接入，我们发现这些第三方支付机构的接入标准和方式存在较大差异，甚至交互模式都有所不同，同时以企业购、拼团为代表的独立业务模块也迅速发展起来，这些业务的订单生命周期和规则不同，存储也比较离散，很难与原有的支付服务中的支付记录建立映射关系。原有架构多个功能模块糅杂在一起显得臃肿并且不好扩展，线上质量也无法保证。因此我们快马加鞭做了架构调整与服务拆分，将支付服务拆分为支付系统和收银台系统，支付系统的范畴缩小到主站订单支付状态管理；而外部支付机构的收银、退款等业务都交给收银台系统负责，将订单与支付信息的关联换成了严选内部唯一的交易流水号。\n        \n        严选收银台架构图\n        通过架构升级，能够实现比较灵活的配置能力，不同帐号在不同产品模块和终端上可以看到不同的收银定制页面，极大的满足了上层业务方的诉求。同时收银台屏蔽了对接第三方的模式差异和复杂性，在设计中将支付通知服务、退款服务全部统一成异步回调模式，降低了上层业务接入的复杂性。\n        中期韬光养晦发展阶段，在支付环节经历架构升级的同时，商品的差异性也开始对下单交易环节产生影响，比如商品类别属性和商品运费。 这里以礼品卡为例，礼品卡是一种特殊的商品，用户购买绑定后可以作为资金在交易环节使用，电子礼品卡不需要履约配送，但是需要对接额外的制卡服务，此外在礼品卡购买过程中还需要根据金额判断是否需要实名认证。在初始的架构中我们对这种商品在交易的每个环节都做特殊处理，但是耦合比较深，随着虚拟商品 (点卡、话费) 和非标准商品 (眼镜、定制品)\n            的不断出现，技术团队对原有架构做了升级，抽象出了交易模板的概念，交易模板可以在结算页面提供定制能力，比如是否可以使用礼品卡、是否可以使用优惠券 / 红包、是否需要用户填写额外的附加信息。不同交易模板产生的订单还会附加上不同的交易标识，用于后续的业务模块对接和订单中心处理。\n        目前百花齐放阶段，我们正在着手的工作是礼品卡平台化，提供可以配置的礼品卡的消耗和逆向策略，使其和支付系统、收银台系统共同构建严选的基础交易服务矩阵。 同时还在考虑扩展交易模板的能力，以其为中心能有效的把下单结算环节和基础交易服务矩阵有效连接在一起，通过平台配置化能力支持不同业务模式下的交易场景。\n        未来，严选规划能在现有交易架构逐渐立体化的情况下更近一步，形成完整的严选交易中心平台，交易中心平台不仅囊括了包括购物车服务，下单服务，支付服务在内的通用交易能力，还将提供完整交易的编排能力，为上层业务提供更加可靠的支持。同时在严选模式往线下拓展的情况下，也在主动探索交易模式的线下场景化，实现线上线下数据打通，为消费者带来更好的购物体验。\n         交易架构实践过程中的技术积累 \n        在严选整个分布式架构演变过程中，一方面很好的满足了系统高可用高吞吐的诉求；另一方面，像大部分互联网公司一样，也碰到分布式架构中常见的数据一致性、资源均衡性等问题。在解决这些问题的过程中，慢慢沉淀出了严选自己的一些中间件。\n         交易流程管理 - 分布式锁和分布式事务 \n        首先来说分布式锁。dlock 是严选可重入、可阻塞、可超时、高可用、高性能、低成本、可弹性伸缩的分布式锁中间件（整体架构如下图所示），其设计目标主要有两个：\n        \n            \n                对分布式环境下资源的访问进行同步，适合多机器、多进程、多线程、单线程等场景；\n            \n            \n                替换高开销、高成本、扩展性差的数据库锁。\n            \n        \n        \n        dlock 可适配多种类型的缓存基础实施，比如 Redis、Memcached、Zookeeper 等，dlock 的容量可根据需求水平伸缩。\n        dlock 支持 3 种不同类型的锁重入策略，分别为：线程级重入、进程级重入、分布式重入，这些重入策略可以完全满足严选业务各复杂场景对对分布式锁的诉求。\n        \n            其次是分布式事务。为了解决交易过程中分布式系统之间数据的一致性，严选自研了分布式事务中间件 DTS。DTS遵循 BASE类型，是一种典型的 TCC(Try/Confirm/Cancel)类型事务，整个 DTS的架构如下图所示：\n            \n            \n                DTS针对两阶段提交做了优化，叫做最末参与者优化 (LPO):分布式事务发起者没有两阶段，只有单阶段，即在所有参与者第一阶段准备好后，它的提交结果直接决定分布式事务的成功与否。\n            \n        \n         交易资源管理 - 核心资源隔离机制与策略 \n        为了拦截刷单、攻击等异常流量，同时也对正常用户流量进行合理限制，严选自研流量限制 & 应急熔断中间件 eudemon。eudemon 将对 CPU、MEM、DB 等资源访问的抽象前移到方法调用、页面访问的层面，通过对方法调用、页面访问的限制间接达到对资源过载的保护。eudemon 的整体架构如下图所示：\n        \n        eudemon 对流量进行了两个层面的控制：\n        \n            \n                拦截刷单和攻击流量：通过对流量主体的行为特征进行分析可以拦截掉 99% 以上的刷单和攻击流量，不让这些黑产流量来与正常流量竞争系统资源，同时减轻下游风控系统的压力。\n            \n            \n                正常流量的控制与熔断：对正常用户流量进行合理限制，削峰填谷，始终保证涌入的流量不超过系统的负载，同时在紧急情况下对业务进行熔断。\n            \n        \n        如何做资源隔离？系统越来越趋向于分布式架构，服务节点越多，级联失败导致单节点故障在分布式架构下被放大。在专注于流入流控 eudemon 之外，严选研发了一个专注于流出流控的资源隔离中间件 aegis。\n        分布式链路中，一个服务依赖的多个下游服务时，因为某一个下游服务不可用或者响应很慢会影响当前服务甚至引起雪崩效应。我们之前线上碰到的比较典型的就慢 SQL，一个慢 SQL 的出现导致数据库的 load 飙升，导致 DB 基本短时突发性不可用，从而导致整个服务或系统的不可用。\n        \n        aegis 的资源隔离流程如上图所示，使用了动态隔离机制，可以按业务维度进行隔离。比如使用分布式数据库的场景，可以只对其中某一个出现故障的 DB Node 进行隔离，而不是对整个分布式数据库进行隔离。\n         总结与思考 - 严选中间件实践的核心理念 \n        严选中间件一直以来都秉承以最低成本解决最核心技术问题的理念，秉承技术驱动业务的信仰，始终以业务为核心做好 360 度支撑。中间件的建设遵循“开源 + 自研”的双引擎模式，开源为主，自研为辅，反馈开源。 站在开源巨人的肩上，可以降低严选的研发成本，通过自研又可以很好的弥补开源的不足，通过反馈开源为开源世界的繁荣反哺严选的技术力量。\n         大促交易中的挑战与应对之道 \n        电商中的大促是对架构设计和平时技术积累的最好考验。作为一种特殊的高并发场景，其峰值往往是平时的数倍甚至几个数量级的差距，一些看似稳定的系统和服务在极端的并发情况下也可能暴露出问题。\n        周期较短的大促活动中，交易链路显得尤为重要，从购物车到下单再到支付，任何一个环节出现故障都可能会影响到运营活动的效果。回顾严选在历次大促中的表现，交易系统面临的主要挑战有这几类：\n        \n            \n                数据库资源的合理使用\n            \n            \n                支付服务的稳定性和及时性\n            \n            \n                外部攻击的防御\n            \n        \n        数据库是交易系统依赖比较重的组件，对数据一致性要求非常高。以下单为例，我们一般会使用事务来保证强一致性，不过随着业务的发展，事务变得臃肿，在高并发场景下性能变差，数据库资源很容易成为瓶颈，轻则影响部分数据节点，重则影响整个下单服务甚至整个交易环节。为了保障大促，严选对事务进行了拆解，梳理出核心业务和非核心业务，非核心业务尽量采用异步化和补偿的机制来完成，核心业务的事务粒度降低到最低，采用分布式锁和分布式事务进行落地。拆解后，事务大小趋于合理，同时在 DDB(网易分布式数据库) 中，选择合适的用户分区策略，把不同用户的事务有效分布到不同的数据库节点上，避免热点问题。\n        支付的稳定性和及时性是另外一个比较大的挑战，大促中如果支付服务发生抖动或者回调不及时都可能在短时间内给用户造成比较大的利益损失，客诉也会增多。在增强监控的前提下，我们还会对资源进行严格的隔离和划分，保留一定的机动性，及时隔离一些服务不稳定的渠道。同时还会准备好主动查询以及重试的策略，在回调发生故障时能够及时切换到备用方式。同时还在用户端做了一个小优化，增加了一个支付处理中的等待文案给用户以安抚。\n        此外，交易系统也可能受到外部攻击的威胁，线上的刷单、刷券等恶意行为时有发生，如果直接使交易接口暴露在攻击下，交易资源就会发生倾斜，严重的可能拖垮整个服务系统。因此我们在交易系统外构建一个可靠的防护罩来保护核心用户的利益。和业界的普遍做法类似，严选的防御也从入口层开始，通过访问特征识别恶意请求进行第一道防御；在业务服务之上，还有了一个接口粒度的防护组件，可以通过 mvel 语法对交易环节的重点接口进行干预；核心交易业务服务逻辑中一般还会接入风控查询接口，对用户进行精准分析。            通过这三层防护，严选的核心链路得到了有效的安全保证。\n        最后说说严选的大促保障流程与策略，主要分为三个阶段。\n        首先是评估阶段，以资源评估准备和压测为主。通过分解大促测算的指标，设定系统关键交易链路的接口吞吐以及响应指标，评估现有系统容量是否满足要求并制定相应的扩容方案。同时在模块压测以及全链路压测中了解服务的现有指标，结合测试报告分析出瓶颈并制定优化方案。\n        然后是准备阶段，在这个阶段我们会详细制定大促交易环节的限流降级以及容灾预案，比如针对秒杀交易场景，也会准备至少两套库存管理方案，当服务出现故障时能够及时进行切换。所有的交易环节确认是否有监控缺失，从购物车到结算页到收银完成针对每一个潜在的交易失败的场景制定相关的发现、解决和补偿计划，并落实到具体负责人身上。预案全部完成后会和测试一起通过全链路压测与局部模块测试进行有效性验证。\n        最后是实施阶段，即便做了充分的准备，线上还是可能出现各种意外的状况，当大促中发生故障时，及时止损是第一原则，这时候准备的限流甚至熔断等预案都是可能派上用场的，同时要立马着手分析原因并做出最小代价的修复方案，即时发布到线上。\n     \n        \n        \n            作者介绍 \n            马超，网易严选技术经理，2013 年加入网易邮件事业部，曾先后参与了多款网易邮箱产品的研发工作。2015 年开始负责严选商城的研发工作，两年以来主导完成了多次技术架构的改造和演变，推动严选业务的高速发展。同时带领团队历经多次大促，保障系统的稳定。在高并发、分布式、业务系统优化和中间件研发等领域有较丰富的实践经验。\n        \n        \n         ', null, null, null, '掘金', 'abd6cdf2-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('2220941f-1551-4920-8204-d803a2eb083c', 'Java集合之HashMap源码解析', '\n    HashMap\n    HashMap 是 Map 的一个实现类，它代表的是一种键值对的数据存储形式。\n    大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。\n    HashMap最多只允许一条记录的键为null，允许多条记录的值为null。不保证有序(比如插入的顺序)、也不保证序不随时间变化。\n    jdk 8 之前，其内部是由数组+链表来实现的，而 jdk 8 对于链表长度超过 8 的链表将转储为红黑树。\n    HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。\n    下面我们先来看一下HashMap内部所用到的存储结构\n    HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的\n    static class Node<K,V> implements Map.Entry<K,V> {\n	final int hash;\n	final K key;\n	V value;\n	Node<K,V> next;\n\n	Node(int hash, K key, V value, Node<K,V> next) {\n		this.hash = hash;\n		this.key = key;\n		this.value = value;\n		this.next = next;\n	}\n\n	public final K getKey()        { return key; }\n	public final V getValue()      { return value; }\n	public final String toString() { return key + \"=\" + value; }\n\n	public final int hashCode() {\n		return Objects.hashCode(key) ^ Objects.hashCode(value);\n	}\n\n	public final V setValue(V newValue) {\n		V oldValue = value;\n		value = newValue;\n		return oldValue;\n	}\n\n	public final boolean equals(Object o) {\n		if (o == this)\n			return true;\n		if (o instanceof Map.Entry) {\n			Map.Entry<?,?> e = (Map.Entry<?,?>)o;\n			if (Objects.equals(key, e.getKey()) &&\n				Objects.equals(value, e.getValue()))\n				return true;\n		}\n		return false;\n	}\n}\n\n    Node是HashMap的一个内部类，实现了Map.Entry接口，本质上就是一个映射(键值对)。\n    有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。\n    HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组。\n    如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞。\n    所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。\n    下面我们就来看一下hashmap中经过jdk1.8优化过的Hash算法和扩容机制。\n    不过在这之前我们先了解下hashmap中的变量\n    //初始化容量16 hashMap的容量必须是2的指数倍，Hashtable是11\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n\n//最大容量2的30次方\nstatic final int MAXIMUM_CAPACITY = 1 << 30;\n\n//默认加载因子默认的平衡因子为0.75，这是权衡了时间复杂度与空间复杂度之后的最好取值\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n// 如果链表的长度超过这个阈值就改用红黑树存储\nstatic final int TREEIFY_THRESHOLD = 8;\n\nstatic final int UNTREEIFY_THRESHOLD = 6;\n\nstatic final int MIN_TREEIFY_CAPACITY = 64;\n\ntransient Node<K,V>[] table;\n\ntransient Set<Map.Entry<K,V>> entrySet;\n\ntransient int size;    //实际存储的键值对个数\n\ntransient int modCount;\n\n //阈值，当table == {}时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。\nint threshold;  \n\nfinal float loadFactor;    //负载因子，代表了table的填充度有多少，默认是0.75\n\n    在HashMap中有两个很重要的参数，容量(Capacity)和负载因子(Load factor)\n    Capacity就是buckets的数目，Load factor就是buckets填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大，也不要把load factor设置过小。当bucket填充的数目（即hashmap中元素的个数）大于capacity*load factor时就需要调整buckets的数目为当前的2倍。\n    Hash算法\n    static final int hash(Object key) {\n	int h;\n	// h = key.hashCode() 为第一步 取hashCode值\n    // h ^ (h >>> 16)  为第二步 高位参与运算\n	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n\nstatic int indexFor(int h, int length) {  \n     return h & (length-1);  //第三步 取模运算\n}\n\n    indexFor是jdk1.7的源码，jdk1.8没有这个方法但是jdk1.8也是通过取模运算来计算的\n    这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。\n    对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，这里我们用&位运算来优化效率。\n    这个方法非常巧妙，它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。\n    在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以Node数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。\n    \n    扩容机制\n    扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。\n    当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。\n    当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。\n    例如我们从16扩展为32时，具体的变化如下所示：\n    \n    因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：\n    \n    因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。\n    这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。\n    final Node<K,V>[] resize() {\n	Node<K,V>[] oldTab = table;    \n	int oldCap = (oldTab == null) ? 0 : oldTab.length;\n	int oldThr = threshold;\n	int newCap, newThr = 0;\n	if (oldCap > 0) {    //说明旧数组已经被初始化完成了，此处需要给旧数组扩容   \n		if (oldCap >= MAXIMUM_CAPACITY) {    如果容量超过Hash Map限定的最大值，将不再扩容\n			threshold = Integer.MAX_VALUE;\n			return oldTab;\n		}    // 没超过最大值，就扩充为原来的2倍\n		else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n				 oldCap >= DEFAULT_INITIAL_CAPACITY)\n			newThr = oldThr << 1;   // 2倍\n	}\n	//数组未初始化，但阈值不为 0，为什么不为 0 ？\n    //构造函数根据传入的容量打造了一个合适的数组容量暂存在阈值中，这里直接使用\n	else if (oldThr > 0) // initial capacity was placed in threshold\n		newCap = oldThr;\n	else {    //数组未初始化并且阈值也为0，说明一切都以默认值进行构造\n		newCap = DEFAULT_INITIAL_CAPACITY;\n		newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n	}    \n	// newCap = oldThr 之后并没有计算阈值，所以 newThr = 0\n	// 重新计算下一次进行扩容的上限\n	if (newThr == 0) {   \n		float ft = (float)newCap * loadFactor;\n		newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n				  (int)ft : Integer.MAX_VALUE);\n	}\n	threshold = newThr;\n	@SuppressWarnings({\"rawtypes\",\"unchecked\"})\n		Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];  //根据新的容量初始化一个数组\n	table = newTab;\n	if (oldTab != null) {\n		for (int j = 0; j < oldCap; ++j) {     // 把每个bucket都移动到新的buckets中\n			Node<K,V> e;\n			if ((e = oldTab[j]) != null) {  //获取头结点\n				oldTab[j] = null;\n				if (e.next == null)   //说明链表或者红黑树只有一个头结点，转移至新表\n					newTab[e.hash & (newCap - 1)] = e;\n				else if (e instanceof TreeNode)  //如果 e 是红黑树结点，红黑树分裂，转移至新表\n					((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n				else {   //这部分是将链表中的各个节点原序地转移至新表中\n					Node<K,V> loHead = null, loTail = null;\n					Node<K,V> hiHead = null, hiTail = null;\n					Node<K,V> next;\n					do {\n						next = e.next;\n						if ((e.hash & oldCap) == 0) {    // 原索引\n							if (loTail == null)\n								loHead = e;\n							else\n								loTail.next = e;\n							loTail = e;\n						}\n						else {                          // 原索引+oldCap\n							if (hiTail == null)\n								hiHead = e;\n							else\n								hiTail.next = e;\n							hiTail = e;\n						}\n					} while ((e = next) != null);\n					if (loTail != null) {      // 原索引放到bucket里\n						loTail.next = null;\n						newTab[j] = loHead;\n					}\n					if (hiTail != null) {     // 原索引+oldCap放到bucket里\n						hiTail.next = null;\n						newTab[j + oldCap] = hiHead;\n					}\n				}\n			}\n		}\n	}\n	return newTab;\n}\n\n    下面我们再来看看hashmap中的其他方法\n    构造函数\n    public HashMap(int initialCapacity, float loadFactor) {\n	if (initialCapacity < 0)\n		throw new IllegalArgumentException(\"Illegal initial capacity: \" +\n										   initialCapacity);\n	if (initialCapacity > MAXIMUM_CAPACITY)\n		initialCapacity = MAXIMUM_CAPACITY;\n	if (loadFactor <= 0 || Float.isNaN(loadFactor))\n		throw new IllegalArgumentException(\"Illegal load factor: \" +\n										   loadFactor);\n	this.loadFactor = loadFactor;\n	this.threshold = tableSizeFor(initialCapacity);\n}\n\n    这是一个最基本的构造函数，需要调用方传入两个参数，initialCapacity 和 loadFactor。\n    程序的大部分代码在判断传入参数的合法性，initialCapacity 小于零将抛出异常，大于 MAXIMUM_CAPACITY 将被限定为 MAXIMUM_CAPACITY。loadFactor 如果小于等于零或者非数字类型也会抛出异常。\n    整个构造函数的核心在对 threshold 的初始化操作：\n    static final int tableSizeFor(int cap) {\n	int n = cap - 1;\n	n |= n >>> 1;\n	n |= n >>> 2;\n	n |= n >>> 4;\n	n |= n >>> 8;\n	n |= n >>> 16;\n	return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n}\n\n    由以上代码可以看出，当在实例化HashMap实例时，如果给定了initialCapacity，由于HashMap的capacity都是2的幂次方，因此这个方法用于找到大于等于initialCapacity的最小的2的幂（initialCapacity如果就是2的幂，则返回的还是这个数）。\n    下面分析这个算法：\n    首先，我们想一下为什么要对cap做减1操作？\n    int n = cap - 1\n\n    这是为了防止，cap已经是2的幂。如果cap已经是2的幂，又没有执行这个减1操作，则执行完后面的几条无符号右移操作之后，返回的capacity将是这个cap的2倍。如果不懂，要看完后面的几个无符号右移之后再回来看看。\n    下面看看这几个无符号右移操作：\n    如果n这时为0了（经过了cap-1之后），则经过后面的几次无符号右移依然是0，最后返回的capacity是1（最后有个n+1的操作）。\n    这里我们只讨论n不等于0的情况。\n    n |= n >>> 1;\n\n    由于n不等于0，则n的二进制表示中总会有一bit为1，这时考虑最高位的1。通过无符号右移1位，则将最高位的1右移了1位，再做或操作，使得n的二进制表示中与最高位的1紧邻的右边一位也为1，如000011xxxxxx。\n    n |= n >>> 2;\n\n    注意，这个n已经进行过 n |= n >>> 1; 操作。假设此时n为000011xxxxxx ，则n无符号右移两位，会将最高位两个连续的1右移两位，然后再与原来的n做或操作，这样n的二进制表示的高位中会有4个连续的1。如00001111xxxxxx 。\n    n |= n >>> 4;\n\n    这次把已经有的高位中的连续的4个1，右移4位，再做或操作，这样n的二进制表示的高位中会有8个连续的1。如00001111 1111xxxxxx 。\n    以此类推 。。。\n    注意，容量最大也就是32bit的正数，因此最后 n |= n >>> 16; 最多也就32个1，但是这时已经大于了MAXIMUM_CAPACITY ，所以取值到MAXIMUM_CAPACITY 。\n    下面我们通过一个图片来看一下整个过程：\n    \n    HashMap 中还有很多的重载构造函数，但几乎都是基于上述的构造函数的。\n    public HashMap(int initialCapacity) {\n	this(initialCapacity, DEFAULT_LOAD_FACTOR);\n}\n\npublic HashMap() {\n	this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted\n}\n\n    以上这些构造函数都没有直接的创建一个切实存在的数组，他们都是在为创建数组需要的一些参数做初始化，所以有些在构造函数中并没有被初始化的属性都会在实际初始化数组的时候用默认值替换。\n    实际对数组进行初始化是在添加元素的时候进行的（即put方法）\n    public HashMap(Map<? extends K, ? extends V> m) {\n	this.loadFactor = DEFAULT_LOAD_FACTOR;\n	putMapEntries(m, false);\n}\n\n    put方法\n    put 方法也是HashMap中比较重要的方法，因为通过该方法我们可以窥探到 HashMap 在内部是如何进行数据存储的，所谓的数组+链表+红黑树的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。\n    put方法的大致实现过程如下：\n    \n        对key的hashCode()做hash，然后再计算index;\n        如果没碰撞直接放到bucket里；\n        如果碰撞了，以链表的形式存在buckets后；\n        如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树；\n        如果节点已经存在就替换old value(保证key的唯一性)\n        如果bucket满了(超过load factor*current capacity)，就要resize。\n    \n    public V put(K key, V value) {    // 对key的hashCode()做hash\n	return putVal(hash(key), key, value, false, true);\n}\n\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n			   boolean evict) {\n	Node<K,V>[] tab; Node<K,V> p; int n, i;\n	if ((tab = table) == null || (n = tab.length) == 0)   // tab为空则创建（初次添加元素）\n		n = (tab = resize()).length;\n	if ((p = tab[i = (n - 1) & hash]) == null)   //根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加 \n		tab[i] = newNode(hash, key, value, null);\n	else {   //如果对应的节点存在元素\n		Node<K,V> e; K k;    \n		if (p.hash == hash &&       //判断table[i]的首个元素是否和key一样，如果相同直接覆盖value\n			((k = p.key) == key || (key != null && key.equals(k))))\n			e = p;\n		else if (p instanceof TreeNode)   //判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对\n			e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n		else {\n		// 遍历table[i]，判断链表长度是否大于TREEIFY_THRESHOLD(默认值为8)，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；\n		// 遍历过程中若发现key已经存在直接覆盖value即可；\n			for (int binCount = 0; ; ++binCount) {\n				if ((e = p.next) == null) {\n					p.next = newNode(hash, key, value, null);\n					if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n						treeifyBin(tab, hash);\n					break;\n				}\n				if (e.hash == hash &&\n					((k = e.key) == key || (key != null && key.equals(k))))\n					break;\n				p = e;\n			}\n		}  //e 不是 null，说明当前的 put 操作是一次修改操作并且e指向的就是需要被修改的结点\n		if (e != null) { // existing mapping for key\n			V oldValue = e.value;\n			if (!onlyIfAbsent || oldValue == null)\n				e.value = value;\n			afterNodeAccess(e);\n			return oldValue;\n		}\n	}\n	++modCount;\n	// 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容\n	if (++size > threshold)\n		resize();\n	afterNodeInsertion(evict);\n	return null;\n}\n\n    get函数实现\n    在理解了put之后，get就很简单了。大致思路如下：\n    bucket里的第一个节点，直接命中；如果有冲突，则通过key.equals(k)去查找对应的entry若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。\n    具体代码的实现如下：\n    public V get(Object key) {\n    Node<K,V> e;\n    return (e = getNode(hash(key), key)) == null ? null : e.value;\n}\nfinal Node<K,V> getNode(int hash, Object key) {\n    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;\n    if ((tab = table) != null && (n = tab.length) > 0 &&\n        (first = tab[(n - 1) & hash]) != null) {\n        // 直接命中\n        if (first.hash == hash && // always check first node\n            ((k = first.key) == key || (key != null && key.equals(k))))\n            return first;\n        // 未命中\n        if ((e = first.next) != null) {\n            // 在树中get\n            if (first instanceof TreeNode)\n                return ((TreeNode<K,V>)first).getTreeNode(hash, key);\n            // 在链表中get\n            do {\n                if (e.hash == hash &&\n                    ((k = e.key) == key || (key != null && key.equals(k))))\n                    return e;\n            } while ((e = e.next) != null);\n        }\n    }\n    return null;\n}\n\n    remove方法\n    删除操作就是一个查找+删除的过程，相对于添加操作其实容易一些\n    public V remove(Object key) {\n    Node<K,V> e;\n    return (e = removeNode(hash(key), key, null, false, true)) == null ?\n        null : e.value;\n}\n\n    根据键值删除指定节点，这是一个最常见的操作了。显然，removeNode 方法是核心。\n    final Node<K,V> removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) {\n    Node<K,V>[] tab; Node<K,V> p; int n, index;\n    if ((tab = table) != null && (n = tab.length) > 0 &&\n        (p = tab[index = (n - 1) & hash]) != null) {\n        Node<K,V> node = null, e; K k; V v;\n        if (p.hash == hash &&\n            ((k = p.key) == key || (key != null && key.equals(k))))\n            node = p;\n        else if ((e = p.next) != null) {\n            if (p instanceof TreeNode)\n                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);\n            else {\n                do {\n                    if (e.hash == hash &&\n                        ((k = e.key) == key ||\n                         (key != null && key.equals(k)))) {\n                        node = e;\n                        break;\n                    }\n                    p = e;\n                } while ((e = e.next) != null);\n            }\n        }\n        if (node != null && (!matchValue || (v = node.value) == value ||(value != null && value.equals(v)))) {\n            if (node instanceof TreeNode)                                                                     ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);\n            else if (node == p)\n                tab[index] = node.next;\n            else\n                p.next = node.next;\n            ++modCount;\n            --size;\n            afterNodeRemoval(node);\n            return node;\n        }\n    }\n    return null;\n}\n\n    删除操作需要保证在表不为空的情况下进行，并且 p 节点根据键的 hash 值对应到数组的索引，在该索引处必定有节点，如果为 null ，那么间接说明此键所对应的结点并不存在于整个 HashMap 中，这是不合法的，所以首先要在这两个大前提下才能进行删除结点的操作。\n    第一步\n    if (p.hash == hash &&((k = p.key) == key || (key != null && key.equals(k))))\n     node = p;\n\n    需要删除的结点就是这个头节点，让 node 引用指向它。否则说明待删除的结点在当前 p 所指向的头节点的链表或红黑树中，于是需要我们遍历查找。\n    第二步\n    else if ((e = p.next) != null) {\n     if (p instanceof TreeNode)\n          node = ((TreeNode<K,V>)p).getTreeNode(hash, key);\n     else {\n         do {\n              if (e.hash == hash &&((k = e.key) == key ||(key != null && key.equals(k)))) {\n                     node = e;\n              break;\n         }\n         p = e;\n         } while ((e = e.next) != null);\n     }\n}\n\n    如果头节点是红黑树结点，那么调用红黑树自己的遍历方法去得到这个待删结点。否则就是普通链表，我们使用 do while 循环去遍历找到待删结点。找到节点之后，接下来就是删除操作了。\n    第三步\n    if (node != null && (!matchValue || (v = node.value) == value ||(value != null && value.equals(v)))) {\n       if (node instanceof TreeNode)\n                    ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);\n       else if (node == p)\n            tab[index] = node.next;\n       else\n            p.next = node.next;\n       ++modCount;\n       --size;\n       afterNodeRemoval(node);\n       return node;\n }\n\n    删除操作也很简单，如果是红黑树结点的删除，直接调用红黑树的删除方法进行删除即可，如果是待删结点就是一个头节点，那么用它的 next 结点顶替它作为头节点存放在 table[index] 中，如果删除的是普通链表中的一个节点，用该结点的前一个节点直接跳过该待删结点指向它的 next 结点即可。\n    最后，如果 removeNode 方法删除成功将返回被删结点，否则返回 null。\n    其他常用方法\n    clear\n    public void clear() {\n    Node<K,V>[] tab;\n    modCount++;\n    if ((tab = table) != null && size > 0) {\n        size = 0;\n        for (int i = 0; i < tab.length; ++i)\n            tab[i] = null;\n    }\n}\n\n    该方法调用结束后将清除 HashMap 中存储的所有元素。\n    keySet\n    //实例属性 keySet\ntransient volatile Set<K>        keySet;\n\npublic Set<K> keySet() {\n    Set<K> ks;\n    return (ks = keySet) == null ? (keySet = new KeySet()) : ks;\n}\nfinal class KeySet extends AbstractSet<K> {\n    public final int size()                 { return size; }\n    public final void clear()               { HashMap.this.clear(); }\n    public final Iterator<K> iterator()     { return new KeyIterator(); }\n    public final boolean contains(Object o) { return containsKey(o); }\n    public final boolean remove(Object key) {\n        return removeNode(hash(key), key, null, false, true) != null;\n    }\n    public final Spliterator<K> spliterator() {\n        return new KeySpliterator<>(HashMap.this, 0, -1, 0, 0);\n    }\n}\n\n    HashMap 中定义了一个 keySet 的实例属性，它保存的是整个 HashMap 中所有键的集合。上述所列出的 KeySet 类是 Set 的一个实现类，它负责为我们提供有关 HashMap 中所有对键的操作。\n    可以看到，KeySet 中的所有的实例方法都依赖当前的 HashMap 实例，也就是说，我们对返回的 keySet 集中的任意一个操作都会直接映射到当前 HashMap 实例中，例如你执行删除一个键的操作，那么 HashMap 中将会少一个节点。\n    values\n    public Collection<V> values() {\n    Collection<V> vs;\n    return (vs = values) == null ? (values = new Values()) : vs;\n}\n\n    values 方法其实和 keySet 方法类似，它返回了所有节点的 value 属性所构成的 Collection 集合，此处不再赘述。\n    entrySet\n    public Set<Map.Entry<K,V>> entrySet() {\n    Set<Map.Entry<K,V>> es;\n    return (es = entrySet) == null ? (entrySet = new EntrySet()) : es;\n}\n\n    它返回的是所有节点的集合，或者说是所有的键值对集合。\n', null, null, null, '掘金', 'a71384ae-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('311e9c37-e064-4db9-b2e3-07eb68cd1d0e', 'nginx中location详解', '\n    \n    作者：chlinwei 原文地址：https://blog.csdn.net/chlinwei/article/details/67631830\n    总览\n    Location block 的基本语法形式是：\n    location [=|~|~*|^~|@] pattern { ... }\n    [=|~|~|^~|@] 被称作* location modifier** ，这会定义 Nginx 如何去匹配其后的 pattern ，以及该 pattern 的最基本的属性（简单字符串或正则表达式）\n    location modifier介绍\n    location =\n    Example:\n    server {    server_name website.com;    location = /abcd {    […]    }}\n    匹配情况：\n    http://website.com/abcd # 正好完全匹配\n    http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配\n    http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2\n    http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），Nginx 不认为这种情况是完全匹配\n    http://website.com/abcde # 不匹配，因为不是完全匹配\n    location (None)\n    可以不写 location modifier ，Nginx 仍然能去匹配 pattern 。这种情况下，匹配那些以指定的 patern 开头的 URI，注意这里的 URI 只能是普通字符串，不能使用正则表达式。\n    Example:\n    server {    server_name website.com;    location /abcd {    […]    }}\n    匹配情况：\n    http://website.com/abcd # 正好完全匹配\n    http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配\n    http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2\n    http://website.com/abcd/ # 末尾存在反斜杠（trailing slash）也属于匹配范围内\n    http://website.com/abcde # 仍然匹配，因为 URI 是以 pattern 开头的\n    location ~\n    这个 location modifier 对大小写敏感，且 pattern 须是正则表达式\n    Example:\n    server {    server_name website.com;    location ~ ^/abcd$ {    […]    }}\n    匹配情况：\n    http://website.com/abcd # 完全匹配\n    http://website.com/ABCD # 不匹配，~ 对大小写是敏感的\n    http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2\n    http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$\n    http://website.com/abcde # 不匹配正则表达式 ^/abcd$\n    \n        注意：对于一些对大小写不敏感的系统，比如 Windows ，~ 和 ~* 都是不起作用的，这主要是操作系统的原因。\n    \n    location ~*\n    与 ~ 类似，但这个 location modifier 不区分大小写，pattern 须是正则表达式\n    Example:\n    server {    server_name website.com;    location ~* ^/abcd$ {    […]    }}\n    匹配情况：\n    http://website.com/abcd # 完全匹配\n    http://website.com/ABCD # 匹配，这就是它不区分大小写的特性\n    http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2\n    http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$\n    http://website.com/abcde # 不匹配正则表达式 ^/abcd$\n    location ^~\n    匹配情况类似 location (None) 的情况，以指定匹配模式开头的 URI 被匹配，不同的是，一旦匹配成功，那么 Nginx 就停止去寻找其他的 Location 块进行匹配了（与 Location 匹配顺序有关）\n    location @\n    用于定义一个 Location 块，且该块不能被外部 Client 所访问，只能被 Nginx 内部配置指令所访问，比如 try_files or error_page\n    搜索顺序以及生效优先级\n    因为可以定义多个 Location 块，每个 Location 块可以有各自的 pattern 。因此就需要明白（不管是 Nginx 还是你），当 Nginx 收到一个请求时，它是如何去匹配 URI 并找到合适的 Location 的。\n    要注意的是，写在配置文件中每个 Server 块中的 Location 块的次序是不重要的，Nginx 会按 location modifier 的优先级来依次用 URI 去匹配 pattern ，顺序如下：\n    1. =2. (None)    如果 pattern 完全匹配 URI（不是只匹配 URI 的头部）3. ^~4. ~ 或 ~*5. (None)    pattern 匹配 URI 的头部\n    匹配案例\n    location  = / {  # 精确匹配 / ，主机名后面不能带任何字符串  [ configuration A ] }location  / {  # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求  # 但是正则和最长字符串会优先匹配  [ configuration B ] }location /documents/ {  # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索  # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条  [ configuration C ] }location ~ /documents/Abc {  # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索  # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条  [ configuration CC ] }location ^~ /images/ {  # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。  [ configuration D ] }location ~* .(gif|jpg|jpeg)$ {  # 匹配所有以 gif,jpg或jpeg 结尾的请求  # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则  [ configuration E ] }location /images/ {  # 字符匹配到 /images/，继续往下，会发现 ^~ 存在  [ configuration F ] }location /images/abc {  # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在  # F与G的放置顺序是没有关系的  [ configuration G ] }location ~ /images/abc/ {  # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用  [ configuration H ] }location ~* /js/.*/.js\n    顺序 no优先级：\n    (location =) > (location 完整路径) > (location ^~ 路径) > (location ~,~* 正则顺序) > (location 部分起始路径) > (/)\n    上面的匹配结果\n    按照上面的location写法，以下的匹配示例成立：\n    / -> config A\n    精确完全匹配，即使/index.html也匹配不了\n    /downloads/download.html -> config B\n    匹配B以后，往下没有任何匹配，采用B\n    /images/1.gif -> configuration D\n    匹配到F，往下匹配到D，停止往下\n    /images/abc/def -> config D\n    最长匹配到G，往下匹配D，停止往下\n    你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序\n    /documents/document.html -> config C\n    匹配到C，往下没有任何匹配，采用C\n    /documents/1.jpg -> configuration E\n    匹配到C，往下正则匹配到E\n    /documents/Abc.jpg -> config CC\n    最长匹配到C，往下正则顺序匹配到CC，不会往下到E\n    实际使用建议\n    所以实际使用中，个人觉得至少有三个匹配规则定义，如下：\n    #直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。\n    #这里是直接转发给后端应用服务器了，也可以是一个静态首页\n    第一个必选规则\n    location = / {    proxy_pass http://tomcat:8080/index}\n    第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项\n    # 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用\n    location ^~ /static/ {    root /webroot/static/;}\n    location ~* .(gif|jpg|jpeg|png|css|js|ico)$ {    root /webroot/res/;}\n    第三个规则就是通用规则，用来转发动态请求到后端应用服务器\n    #非静态文件请求就默认是动态请求，自己根据实际把握\n    location / {    proxy_pass http://tomcat:8080/}\n    \n    如果读完觉得有收获的话，欢迎点赞、关注、加公众号【匠心零度】，查阅更多精彩历史！！！\n    \n', null, null, null, '掘金', 'a8f6f026-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('3156d6fe-c74c-430f-98fa-d6b5ee6ffd13', '关于Golang过滤敏感信息的正确姿势', 'None', null, null, null, '掘金', 'add37d76-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('67ad19a6-0a81-458a-b1a8-3d60698044ff', '详解Spring Retry实现原理', '本文通过一个简单的例子演示Spring Retry的实现原理，例子中定义的注解只包含重试次数属性，实际上Spring Retry中注解可设置属性要多的多，单纯为了讲解原理，所以弄简单点，关于Spring Retry可查阅相关文档、博客。注解定义package org.java.base.springretry;\n\nimport java.lang.annotation.*;\n\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface Retryable {\n\n int maxAttemps() default 0;\n\n}\n代理实现以Cglib作为代理工具，先来写个Callback实现，这也是重试的实现的核心逻辑package org.java.base.springretry;\n\nimport java.lang.reflect.Method;\n\nimport org.springframework.cglib.proxy.MethodInterceptor;\nimport org.springframework.cglib.proxy.MethodProxy;\n\npublic class AnnotationAwareRetryOperationsInterceptor implements MethodInterceptor{\n\n //记录重试次数\n private int times = 0;\n\n @Override\n public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n //获取拦截的方法中的Retryable注解\n Retryable retryable = method.getAnnotation(Retryable.class);\n if(retryable == null){\n return proxy.invokeSuper(obj,args);\n }else{ //有Retryable注解，加入异常重试逻辑\n int maxAttemps = retryable.maxAttemps();\n try {\n return proxy.invokeSuper(obj,args);\n } catch (Throwable e) {\n if(times++ == maxAttemps){\n System.out.println(\"已达最大重试次数：\" + maxAttemps + \",不再重试！\");\n }else{\n System.out.println(\"调用\" + method.getName() + \"方法异常，开始第\" + times +\"次重试。。。\");\n //注意这里不是invokeSuper方法，invokeSuper会退出当前interceptor的处理\n proxy.invoke(obj,args);\n }\n }\n }\n return null;\n }\n}\n然后是写个代理类，使用AnnotationAwareRetryOperationsInterceptor作为拦截器package org.java.base.springretry;\nimport org.springframework.cglib.proxy.Enhancer;\n\npublic class SpringRetryProxy {\n\n public Object newProxyInstance(Object target){\n Enhancer enhancer = new Enhancer();\n enhancer.setSuperclass(target.getClass());\n enhancer.setCallback(new AnnotationAwareRetryOperationsInterceptor());\n return enhancer.create();\n }\n} 测试通过一个用户相关的业务方法来测试上面的代码接口定义：package org.java.base.springretry;\npublic interface UserService {\n\n void add() throws Exception;\n\n void query() throws Exception;\n}\n接口实现：package org.java.base.springretry;\npublic class UserServiceImpl implements UserService {\n @Override\n public void add() throws Exception {\n System.out.println(\"添加用户。。。\");\n throw new RuntimeException();\n }\n\n @Override\n @Retryable(maxAttemps = 3)\n public void query() {\n System.out.println(\"查询用户。。。\");\n throw new RuntimeException();\n }\n}测试：package org.java.base.springretry;\npublic class TestRetry {\n\n public static void main(String[] args) throws Exception{\n UserServiceImpl user = new UserServiceImpl();\n //SpringRetry代理测试\n SpringRetryProxy springRetryProxy = new SpringRetryProxy();\n UserService u = (UserService)springRetryProxy.newProxyInstance(user);\n //u.add();//失败不重试\n u.query();//失败重试\n }\n}\nadd方法不添加重试注解，程序异常结束，query方法添加重试注解，设置重试3次，运行效果如下以上就是本文的全部内容，希望对大家的学习有所帮助，也希望大家多多支持我们。', null, null, null, '掘金', 'a958f5a0-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('6a13231b-2f5f-4763-bcfd-6330af9d4d7b', '阿里巴巴为什么不用 ZooKeeper 做服务发现？', '\n    \n                     \n        站在未来的路口，回望历史的迷途，常常会很有意思，因为我们会不经意地兴起疯狂的念头，例如如果当年某事提前发生了，而另外一件事又没有发生会怎样？一如当年的奥匈帝国皇位继承人斐迪南大公夫妇如果没有被塞尔维亚族热血青年普林西普枪杀会怎样，又如若当年的丘老道没有经过牛家村会怎样？\n        2008 年底，淘宝开启一个叫做“五彩石”的内部重构项目，这个项目后来成为了淘宝服务化、面向分布式走自研之路，走出了互联网中间件体系之始，而淘宝服务注册中心 ConfigServer 于同年诞生。\n        2008 年前后，Yahoo 这个曾经的互联网巨头开始逐渐在公开场合宣讲自己的大数据分布式协调产品 ZooKeeper，这个产品参考了 Google 发表的关于 Chubby 以及 Paxos 的论文。\n        2010 年 11 月，ZooKeeper 从 Apache Hadoop 的子项目发展为 Apache 的顶级项目，正式宣告 ZooKeeper 成为一个工业级的成熟稳定的产品。\n        2011 年，阿里巴巴开源 Dubbo，为了更好开源，需要剥离与阿里内部系统的关系，Dubbo 支持了开源的 ZooKeeper 作为其注册中心，后来在国内，在业界诸君的努力实践下，Dubbo + ZooKeeper 的典型的服务化方案成就了 ZooKeeper 作为注册中心的声名。\n        2015 年双 11，ConfigServer 服务内部近 8 个年头过去了，阿里巴巴内部“服务规模”超几百万 ，以及推进“千里之外”的 IDC 容灾技术战略等，共同促使阿里巴巴内部开启了 ConfigServer 2.0 到 ConfigServer 3.0 的架构升级之路。\n        时间走向 2018 年，站在 10 年的时间路口上，有多少人愿意在追逐日新月异的新潮技术概念的时候，稍微慢一下脚步，仔细凝视一下服务发现这个领域，有多少人想到过或者思考过一个问题：\n        服务发现，ZooKeeper 真的是最佳选择么？\n        而回望历史，我们也偶有迷思，在服务发现这个场景下，如果当年 ZooKeeper 的诞生之日比我们 HSF 的注册中心 ConfigServer 早一点会怎样？\n        我们会不会走向先使用 ZooKeeper 然后疯狂改造与修补 ZooKeeper 以适应阿里巴巴的服务化场景与需求的弯路？\n        但是，站在今天和前人的肩膀上，我们从未如今天这样坚定的认知到，在服务发现领域，ZooKeeper 根本就不能算是最佳的选择，一如这些年一直与我们同行的 Eureka 以及这篇文章 《Eureka! Why You Shouldn’t Use ZooKeeper for Service Discovery》那坚定的阐述一样，为什么你不应该用 ZooKeeper 做服务发现！\n        吾道不孤矣。\n         注册中心需求分析及关键设计考量 \n        接下来，让我们回归对服务发现的需求分析，结合阿里巴巴在关键场景上的实践，来一一分析，一起探讨为何说 ZooKeeper 并不是最合适的注册中心解决方案。\n         注册中心是 CP 还是 AP 系统? \n        CAP 和 BASE 理论相信读者都已经耳熟能详，其业已成了指导分布式系统及互联网应用构建的关键原则之一，在此不再赘述其理论，我们直接进入对注册中心的数据一致性和可用性需求的分析:\n        \n            \n                数据一致性需求分析\n            \n        \n        注册中心最本质的功能可以看成是一个 Query 函数 Si = F(service-name)，以 service-name 为查询参数，service-name 对应的服务的可用的 endpoints (ip:port) 列表为返回值.\n        \n            注: 后文将 service 简写为 svc。\n        \n        先来看看关键数据 endpoints (ip:port) 不一致性带来的影响，即 CAP 中的 C 不满足带来的后果 :\n        如上图所示，如果一个\n            svcB 部署了 10 个节点 (副本 /Replica），如果对于同一个服务名 svcB, 调用者 svcA 的 2 个节点的 2 次查询返回了不一致的数据，例如: S1 = { ip1,ip2,ip3...,ip9 }, S2 = { ip2,ip3,....ip10 }, 那么这次不一致带来的影响是什么？相信你一定已经看出来了，svcB 的各个节点流量会有一点不均衡。\n        ip1 和 ip10 相对其它 8 个节点{ip2...ip9}，请求流量小了一点，但很明显，在分布式系统中，即使是对等部署的服务，因为请求到达的时间，硬件的状态，操作系统的调度，虚拟机的 GC 等，任何一个时间点，这些对等部署的节点状态也不可能完全一致，而流量不一致的情况下，只要注册中心在 SLA 承诺的时间内（例如 1s 内）将数据收敛到一致状态（即满足最终一致），流量将很快趋于统计学意义上的一致，所以注册中心以最终一致的模型设计在生产实践中完全可以接受。\n        \n            \n                分区容忍及可用性需求分析\n            \n        \n        接下来我们看一下网络分区（Network Partition）情况下注册中心不可用对服务调用产生的影响，即 CAP 中的 A 不满足时带来的影响。\n        考虑一个典型的 ZooKeeper 三机房容灾 5 节点部署结构 (即 2-2-1 结构)，如下图:\n        \n        当机房 3 出现网络分区 (Network Partitioned) 的时候，即机房 3 在网络上成了孤岛，我们知道虽然整体 ZooKeeper 服务是可用的，但是节点 ZK5 是不可写的，因为联系不上 Leader。\n        也就是说，这时候机房 3 的应用服务 svcB 是不可以新部署，重新启动，扩容或者缩容的，但是站在网络和服务调用的角度看，机房 3 的 svcA 虽然无法调用机房 1 和机房 2 的 svcB, 但是与机房 3 的 svcB 之间的网络明明是 OK 的啊，为什么不让我调用本机房的服务？\n        现在因为注册中心自身为了保脑裂 (P) 下的数据一致性（C）而放弃了可用性，导致了同机房的服务之间出现了无法调用，这是绝对不允许的！可以说在实践中，注册中心不能因为自身的任何原因破坏服务之间本身的可连通性，这是注册中心设计应该遵循的铁律！ 后面在注册中心客户端灾容上我们还会继续讨论。\n        同时我们再考虑一下这种情况下的数据不一致性，如果机房 1，2，3 之间都成了孤岛，那么如果每个机房的 svcA 都只拿到本机房的 svcB 的 ip 列表，也即在各机房 svcB 的 ip 列表数据完全不一致，影响是什么？\n        其实没啥大影响，只是这种情况下，全都变成了同机房调用，我们在设计注册中心的时候，有时候甚至会主动利用这种注册中心的数据可以不一致性，来帮助应用主动做到同机房调用，从而优化服务调用链路 RT 的效果！\n        通过以上我们的阐述可以看到，在 CAP 的权衡中，注册中心的可用性比数据强一致性更宝贵，所以整体设计更应该偏向 AP，而非 CP，数据不一致在可接受范围，而 P 下舍弃 A 却完全违反了注册中心不能因为自身的任何原因破坏服务本身的可连通性的原则。\n         服务规模、容量、服务联通性 \n        你所在公司的“微服务”规模有多大？数百微服务？部署了上百个节点？那么 3 年后呢？互联网是产生奇迹的地方，也许你的“服务”一夜之间就家喻户晓，流量倍增，规模翻番！\n        当数据中心服务规模超过一定数量 (服务规模 =F{服务 pub 数, 服务 sub 数})，作为注册中心的 ZooKeeper 很快就会像下图的驴子一样不堪重负\n        \n        其实当 ZooKeeper 用对地方时，即用在粗粒度分布式锁，分布式协调场景下，ZooKeeper 能支持的 tps 和支撑的连接数是足够用的，因为这些场景对于 ZooKeeper 的扩展性和容量诉求不是很强烈。\n        但在服务发现和健康监测场景下，随着服务规模的增大，无论是应用频繁发布时的服务注册带来的写请求，还是刷毫秒级的服务健康状态带来的写请求，还是恨不能整个数据中心的机器或者容器皆与注册中心有长连接带来的连接压力上，ZooKeeper 很快就会力不从心，而 ZooKeeper 的写并不是可扩展的，不可以通过加节点解决水平扩展性问题。\n        要想在 ZooKeeper 基础上硬着头皮解决服务规模的增长问题，一个实践中可以考虑的方法是想办法梳理业务，垂直划分业务域，将其划分到多个 ZooKeeper 注册中心，但是作为提供通用服务的平台机构组，因自己提供的服务能力不足要业务按照技术的指挥棒配合划分治理业务，真的可行么？\n        而且这又违反了因为注册中心自身的原因（能力不足）破坏了服务的可连通性，举个简单的例子，1 个搜索业务，1 个地图业务，1 个大文娱业务，1 个游戏业务，他们之间的服务就应该老死不相往来么？也许今天是肯定的，那么明天呢，1 年后呢，10 年后呢？谁知道未来会要打通几个业务域去做什么奇葩的业务创新？注册中心作为基础服务，无法预料未来的时候当然不能妨碍业务服务对未来固有联通性的需求。\n         注册中心需要持久存储和事务日志么？ \n        需要，也不需要。\n        我们知道 ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，以及宕机之后的数据可恢复，这是非常好的特性，但是我们要问，在服务发现场景中，其最核心的数据 - 实时的健康的服务的地址列表真的需要数据持久化么？\n        对于这份数据，答案是否定的。\n        \n        如上图所示，如果 svcB 经历了注册服务 (ip1) 到扩容到 2 个节点（ip1，ip2）到因宕机缩容 (ip1 宕机），这个过程中，产生了 3 次针对 ZooKeeper 的写操作。\n        但是仔细分析，通过事务日志，持久化连续记录这个变化过程其实意义不大，因为在服务发现中，服务调用发起方更关注的是其要调用的服务的实时的地址列表和实时健康状态，每次发起调用时，并不关心要调用的服务的历史服务地址列表、过去的健康状态。\n        但是为什么又说需要呢，因为一个完整的生产可用的注册中心，除了服务的实时地址列表以及实时的健康状态之外，还会存储一些服务的元数据信息，例如服务的版本，分组，所在的数据中心，权重，鉴权策略信息，service label 等元信息，这些数据需要持久化存储，并且注册中心应该提供对这些元信息的检索的能力。\n         Service Health Check \n        使用 ZooKeeper 作为服务注册中心时，服务的健康检测常利用 ZooKeeper 的 Session 活性 Track 机制 以及结合 Ephemeral ZNode 的机制，简单而言，就是将服务的健康监测绑定在了 ZooKeeper 对于 Session 的健康监测上，或者说绑定在 TCP 长链接活性探测上了。\n        这在很多时候也会造成致命的问题，ZK 与服务提供者机器之间的 TCP 长链接活性探测正常的时候，该服务就是健康的么？答案当然是否定的！注册中心应该提供更丰富的健康监测方案，服务的健康与否的逻辑应该开放给服务提供方自己定义，而不是一刀切搞成了 TCP 活性检测！\n        健康检测的一大基本设计原则就是尽可能真实的反馈服务本身的真实健康状态，否则一个不敢被服务调用者相信的健康状态判定结果还不如没有健康检测。\n         注册中心的容灾考虑 \n        前文提过，在实践中，注册中心不能因为自身的任何原因破坏服务之间本身的可连通性，那么在可用性上，一个本质的问题，如果注册中心（Registry）本身完全宕机了，svcA 调用 svcB 链路应该受到影响么？\n        \n        是的，不应该受到影响。\n        服务调用（请求响应流）链路应该是弱依赖注册中心，必须仅在服务发布，机器上下线，服务扩缩容等必要时才依赖注册中心。\n        这需要注册中心仔细的设计自己提供的客户端，客户端中应该有针对注册中心服务完全不可用时做容灾的手段，例如设计客户端缓存数据机制（我们称之为 client snapshot）就是行之有效的手段。另外，注册中心的 health check 机制也要仔细设计以便在这种情况不会出现诸如推空等情况的出现。\n        ZooKeeper 的原生客户端并没有这种能力，所以利用 ZooKeeper 实现注册中心的时候我们一定要问自己，如果把 ZooKeeper 所有节点全干掉，你生产上的所有服务调用链路能不受任何影响么？而且应该定期就这一点做故障演练。\n         你有没有 ZooKeeper 的专家可依靠？ \n        ZooKeeper 看似很简单的一个产品，但在生产上大规模使用并且用好，并不是那么理所当然的事情。如果你决定在生产中引入 ZooKeeper，你最好做好随时向 ZooKeeper 技术专家寻求帮助的心理预期，最典型的表现是在两个方面:\n        \n            \n                难以掌握的 Client/Session 状态机\n            \n        \n        ZooKeeper 的原生客户端绝对称不上好用，Curator 会好一点，但其实也好的有限，要完全理解 ZooKeeper 客户端与 Server 之间的交互协议也并不简单，完全理解并掌握 ZooKeeper Client/Session 的状态机（下图）也并不是那么简单明了:\n        \n        但基于 ZooKeeper 的服务发现方案却是依赖 ZooKeeper 提供的长连接 /Session 管理，Ephemeral ZNode，Event&Notification, ping 机制上，所以要用好 ZooKeeper 做服务发现，恰恰要理解这些 ZooKeeper 核心的机制原理，这有时候会让你陷入暴躁，我只是想要个服务发现而已，怎么要知道这么多？而如果这些你都理解了并且不踩坑，恭喜你，你已经成为 ZooKeeper 的技术专家了。\n        \n            \n                难以承受的异常处理\n            \n        \n        我们在阿里巴巴内部应用接入 ZooKeeper 时，有一个《ZooKeeper 应用接入必知必会》的 WIKI，其中关于异常处理有过如下的论述:\n        \n            如果说要选出应用开发者在使用 ZooKeeper 的过程中，最需要了解清楚的事情？那么根据我们之前的支持经验，一定是异常处理。\n            当所有一切（宿主机，磁盘，网络等等）都很幸运的正常工作的时候，应用与 ZooKeeper 可能也会运行的很好，但不幸的是，我们整天会面对各种意外，而且这遵循墨菲定律，意料之外的坏事情总是在你最担心的时候发生。\n            所以务必仔细了解 ZooKeeper 在一些场景下会出现的异常和错误，确保您正确的理解了这些异常和错误，以及知道您的应用如何正确的处理这些情况。\n            \n                \n                    ConnectionLossException 和 Disconnected 事件\n                \n            \n            简单来说，这是个可以在同一个 ZooKeeper Session 恢复的异常 (Recoverable), 但是应用开发者需要负责将应用恢复到正确的状态。\n            发生这个异常的原因有很多，例如应用机器与 ZooKeeper 节点之间网络闪断，ZooKeeper 节点宕机，服务端 Full GC 时间超长，甚至你的应用进程 Hang 死，应用进程 Full GC 时间超长之后恢复都有可能。\n            要理解这个异常，需要了解分布式应用中的一个典型的问题，如下图：\n            在一个典型的客户端请求、服务端响应中，当它们之间的长连接闪断的时候，客户端感知到这个闪断事件的时候，会处在一个比较尴尬的境地，那就是无法确定该事件发生时附近的那个请求到底处在什么状态，Server 端到底收到这个请求了么？已经处理了么？因为无法确定这一点，所以当客户端重新连接上 Server 之后，这个请求是否应该重试（Retry）就也要打一个问号。\n            所以在处理连接断开事件中，应用开发者必须清楚处于闪断附近的那个请求是什么（这常常难以判断），该请求是否是幂等的，对于业务请求在 Server 端服务处理上对于\"仅处理一次\" \"最多处理一次\" \"最少处理一次\"语义要有选择和预期。\n            举个例子，如果应用在收到 ConnectionLossException 时，之前的请求是 Create 操作，那么应用的 catch 到这个异常，应用一个可能的恢复逻辑就是，判断之前请求创建的节点的是否已经存在了，如果存在就不要再创建了，否则就创建。\n            再比如，如果应用使用了 exists Watch 去监听一个不存在的节点的创建的事件，那么在 ConnectionLossException 的期间，有可能遇到的情况是，在这个闪断期间，其它的客户端进程可能已经创建了节点，并且又已经删除了，那么对于当前应用来说，就 miss 了一次关心的节点的创建事件，这种 miss 对应用的影响是什么？是可以忍受的还是不可接受？需要应用开发者自己根据业务语义去评估和处理。\n            \n                \n                    SessionExpiredException 和 SessionExpired 事件\n                \n            \n            Session 超时是一个不可恢复的异常，这是指应用 Catch 到这个异常的时候，应用不可能在同一个 Session 中恢复应用状态，必须要重新建立新 Session，老 Session 关联的临时节点也可能已经失效，拥有的锁可能已经失效。...\n        \n        我们阿里巴巴的小伙伴在自行尝试使用 ZooKeeper 做服务发现的过程中，曾经在我们的内网技术论坛上总结过一篇自己踩坑的经验分享\n        \n        在该文中中肯的提到:\n        ... 在编码过程中发现很多可能存在的陷阱，毛估估，第一次使用 zk 来实现集群管理的人应该有 80% 以上会掉坑，有些坑比较隐蔽，在网络问题或者异常的场景时才会出现，可能很长一段时间才会暴露出来 ...\n        这篇文章已经分享到云栖社区, 你可以点击 这里 详细阅读。\n         向左走，向右走 \n        阿里巴巴是不是完全没有使用 ZooKeeper？并不是！\n        熟悉阿里巴巴技术体系的都知道，其实阿里巴巴维护了目前国内乃至世界上最大规模的 ZooKeeper 集群，整体规模有近千台的 ZooKeeper 服务节点。\n        同时阿里巴巴中间件内部也维护了一个面向大规模生产的、高可用、更易监控和运维的 ZooKeeper 的代码分支 TaoKeeper，如果以我们近 10 年在各个业务线和生产上使用 ZooKeeper 的实践，给 ZooKeeper 用一个短语评价的话，那么我们认为 ZooKeeper 应该是 “The King Of Coordination for Big Data”！\n        \n        在粗粒度分布式锁，分布式选主，主备高可用切换等不需要高 TPS 支持的场景下有不可替代的作用，而这些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时间分任务多进程 / 线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就是 ZooKeeper 发挥巨大作用的用武之地。\n        但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然的短板，应该竭力避免在这些场景下引入 ZooKeeper，在阿里巴巴的生产实践中，应用对 ZooKeeper 申请使用的时候要进行严格的场景、容量、SLA 需求的评估。\n        所以可以使用 ZooKeeper，但是大数据请向左，而交易则向右，分布式协调向左，服务发现向右。\n         结语 \n        感谢你耐心的阅读到这里，至此，我相信你已经理解，我们写这篇文章并不是全盘否定 ZooKeeper，而只是根据我们阿里巴巴近 10 年来在大规模服务化上的生产实践，对我们在服务发现和注册中心设计及使用上的经验教训进行一个总结，希望对业界就如何更好的使用 ZooKeeper，如何更好的设计自己的服务注册中心有所启发和帮助。\n        最后，条条大路通罗马，衷心祝愿你的注册中心直接就诞生在罗马。\n        参考文章\n        [1]https://medium.com/knerd/eureka-why-you-shouldnt-use-zookeeper-for-service-discovery-4932c5c7e764\n        [2]https://yq.aliyun.com/articles/227260\n        \n        如果，Google 早已解决不了你的问题。\n        如果，你还想知道 Apple、Facebook、IBM、阿里等国内外名企的核心架构设计。\n        来，我们在深圳准备了 ArchSummit 全球架构师峰会，想和你分享：\n        \n            \n                微信百亿消息背后的万级机器是怎么做 AI 调度的\n            \n            \n                滴滴三核心引擎之一的地图，如何计算路径规划和道路匹配\n            \n            \n                微博如何做万亿级关系的实时协同推荐\n            \n            \n                微众区块链首席架构师的两个具体案例实操\n            \n            \n                罗辑思维 Go 语言微服务完整改造全过程\n            \n            \n                阿里菜鸟全球跨域 RPC 架构设计\n            \n            \n                前特斯拉视觉深度学习负责人带来的核心技术解析\n            \n            \n                微服务楷模 Netflix 在 FaaS 上的最新实践\n            \n        \n        \n    \n', null, null, null, '掘金', 'a3238b8c-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('d9e54091-7af9-448b-b3b7-f39a85511c25', '唯品会 Java 核心项目 VJTools 开源', '\n    VJTools，是主力于Java的唯品会，关于Java的一些小家底：《唯品会Java开发手册》，核心基础类库 ，问题排查小工具。各位看官看着是好的，烦请“Star” :\n    \n        github.com/vipshop/vjt…\n    \n     \n    1.《唯品会Java开发手册》\n    《阿里巴巴Java开发手册》，是首个对外公布的企业级Java开发手册, 意义重大。\n    我们结合唯品会的内部经验，参考《Clean Code》、《Effective Java》等重磅资料，增补了一些条目，同时删减了一些相对不那么通用的规则，让规范更精炼易记。\n    比如：《注释规约》中“所有的类都必须添加创建者和创建日期”，我们觉得一份代码必然经过很多人的维护，修改者纪录交给GIT更好。\n    在不断的改写中，规范变得更暗，更亮，更薄，更厚，更浑浊，更清澈，更混合，更纯粹...感谢阿里授权我们的任性修改。\n     \n    2. 核心类库VJKit\n    综合众多开源类库的精华而成， 让开发人员避免底层代码的重复开发，默认就拥有最佳实践，尤其在性能的方面。\n    针对“文本，数字，日期，文件，集合，并发，反射”这些开发人员的日常，VJKit做了两件事情：\n    一是对Guava与Common Lang中最常用API的提炼归类，避免了大家直面茫茫多的API。\n    二是对各门各派的精华的借鉴移植，比如一些大项目的附送基础库如Netty，ElasticSearch，一些专业的基础库如Jodd，一些大厂的基础库如Facebook和Twitter。\n     \n    3. 工具集－VJMap\n    分代版的jmap（新生代，存活区，老生代），是排查内存缓慢泄露，老生代增长过快原因的利器。\n    jmap -histo PID 打印的是整个Heap的对象统计信息，而为了定位上面的问题，我们需要专门查看OldGen对象，和Survivor区老龄剩男的工具。\n    致敬R大，思路来源于TBJMap，翻新后支持JDK8，支持Survivor区老龄对象过滤，以及大天秤对输出结果不要看歪脖子的执着。\n    此处有一实战：【唯实践】JVM老生代增长过快问题排查，最后定位是Jedis的锅。\n     \n    4. 工具集－VJTop\n    若你习惯以Top观察 “OS指标及繁忙的进程”，也推荐以VJTop观看 “JVM指标及CPU最繁忙，占用内存最多的线程”。\n    在jvmtop之上二次开发，又结合SJK的思路，从/proc ， PerfData，JMX等处，以更高的性能，获取更多的信息。\n     \n    最后的话\n    SpringSide之后好久没开源新项目，希望大家继续支持，不需要打赏，Github点星是最好的支持。\n    VJTools官方微信讨论群，请搜索微信号viptech128(唯技术)，添加好友后加入。\n    对于优秀的建议和Pull Request代码提交，唯品会将不吝发挥电商本色，给予vip.com购物卡的奖励 ！！！\n    有关的...\n    \n        2016-11-26 -- 关于Java集合的小抄\n        2015-04-21 -- JDK数则\n    \n', null, null, null, '掘金', 'af3b8c94-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('fe9ff561-c93b-4cf0-a31e-d7f28ec4dfde', 'Netty源码分析——Reactor的task', 'None', null, null, null, '掘金', 'ad418902-6a3b-11e8-8580-000c29753dbb');
INSERT INTO `nsnews` VALUES ('feef13d6-5ed3-4012-8f49-deec3133114d', 'Laravel 程序架构设计思路：使用动作类', '\n    \n    当我们谈论到应用程序的架构的时候，经常会问到一个经典的问题，那就是“这段代码应该放在哪里比较好”。 因为 Laravel 是一个相当灵活的框架，所以要回答这个问题其实没那么容易。我应该把我的业务逻辑写在 Model 层，还是 Controller 层，或者是其他地方？\n    当你的应用程序仅有一个接入点，把业务逻辑写在 Controller 层是可以的。但是现在更普遍的的情形是，有很多接入点去调用相同的功能模块。\n    比如说，太多数的应用程序都有用户注册的功能，它的流程是调用一个控制器然后返回一个注册成功或者失败的视图。假如这个应用程序还有移动端，那就很可能要提供一套针对移动端用户注册的 API ，因为它需要返回的数据格式是 JSON 。而且利用 Laravel 的 artisan 命令来创建用户也很常见，尤其是在项目前期的开发阶段。\n    \n    上面这两段代码可能看起来没有什么问题的，但是，随着业务逻辑的增加，就会显得代码很冗余。举个例子，如果你需要新用户注册完之后，增加给用户发送邮件通知的功能，你必须要再上面两个控制器中都添加发送邮件的代码。但是如果要保持代码的简洁优雅，我们可以把这些业务逻辑写到其他地方。\n    对于“把业务逻辑代码写到哪里”的这个问题，你去任何论坛都可以得到一个普遍的答案，那就是 “使用一个 service 层，然后在 controller 层调用这个服务类”。是的，没错，问题是我们应该怎么设计 service 类？是创建一个 UserService 类来实现所有跟用户用户有关的业务逻辑，然后把这个类注入到需要用到的 Controller 层？或者是还有其他方案？\n    避免神类的坑\n    首先，可以尝试为一个特定的模型创建一个单一类，其中包含所有的代码。例如：\n    \n    看起来很完美：我们可以任何控制器中申明或者使用 create/delete 方法，并且得到我们想要的结果。但是，这种实现有什么问题呢？ 那就是我们在解决问题的过程通常很少使用单一的模型  。\n    比如说，当我们给一个用户创建了账号的时候，也要同时给用户单独创建一个 blog 。如果按照当前的方式去实现这个流程，我们就必须创建一个 BlogService 类，然后将其依赖注入到 UserService 类。\n    \n    显而易见，随着应用程序的业务的增长，将会有几十到上百个 service 类，其中的一些 service 类需要依赖 5 到 6 个其他 service 类，最终的结果就是，出现代码的冗余跟混乱的局面，而这个局面是我们想不惜一切代价去避免的。\n    介绍单动作类\n    那么，如果不是用一个单一的服务类加上几个方法，我们决定把它分成几个类？下面是我最近每一个项目都采用的方法，结果很不错，推荐给大家。\n    首先，让我们抛弃过于笼统和模糊的服务术语，来了解一下我们的新动作类，并定义它们是什么以及它们可以做什么。\n    \n        一个动作类，应该有一个能够说明其功能的名字，比如：CreateOrder, ConfirmCheckout, DeleteProduct, AddProductToCart等。\n        它应该有且只有一个公共方法，作为 API 。理想的情况下，应该是相同的方法名，像 handle() 或者 execute() 。如果需要对我们的动作类实现某种适配器模式，这是非常方便的。\n        它必须对请求和响应不可知。它不处理请求，也不发送响应。这样的职责应该由控制器来承担。\n        它可以依赖其它的动作类。\n        如果有任何事情阻止它执行和/或返回期望的值，那么它必须通过抛出一个 Exception 来强制执行相关的业务逻辑，并且让调用者（或者 Laravel 的 ExceptionHandler ）来承担如何呈现/响应异常的责任。\n    \n    创建我们的 CreateUser 动作类\n    现在，让我们看看前面的例子，并用一个单动作类来重构它，我们将命名为 CreateUser 。\n    \n    你或许想知道当邮箱地址已经被占用时，该方法为什么会抛出了异常。 这难道不是请求验证来保证的吗？当然可以。然而，在动作类内部来执行业务逻辑不是更好吗？这样使得逻辑变得易于理解和调试。\n    让我们看看使用我们动作类之后的控制器代码，如下：\n    \n    现在，无论我们做什么修改，用户注册过程都会由 API 和 Web 版本处理，优雅整洁。\n    动作类的嵌套\n    假如，我们需要一个动作类将 1000 个用户导入我们的应用中。我们可以写一个动作类，并且继续使用上文的 CreateUser 类：\n    \n    非常整洁，不是吗？我们可以通过将其嵌入在 Collection::map() 方法中来重用 CreateUser 代码，然后返回所有新建用户的集合。当邮件被占用的时候，我们可以通过返回 Null Object 或者在 Log 文件中记录一下，你应该已经想到了。\n    动作类的装饰\n    现在，假设我们想在日志中记录每一个新注册的用户。我们可以将代码写在动作类内部，也可以使用装饰者模式。\n    \n    然后，我们可以使用 Laravel 的 IoC 容器将 LogCreateUser 类绑定到 CreateUser 类，所有每当我们需要一个后者的实例时，前者都会注入进来：\n    \n    AppServiceProvider.php\n    这使得使用配置或环境变量来控制日志记录功能的激活或停用更为方便：\n    \n    AppServiceProvider.php\n    总结\n    使用这个方法似乎会需要很多的类。当然，用户注册仅仅是一个简单的例子，旨在保证代码的简短清晰。一旦项目的复杂度开始增长，动作类的真正的价值就越来越明显，因为你清晰的知道代码所在及其界定。\n    使用单动作类的好处：\n    \n        小巧而单一的逻辑域能够防止代码重复并提高代码的可重用性，保持稳定。\n        易于针对各种场景进行独立测试。\n        富有意义的命名在大型项目中更容易阅读。\n        易于装饰。\n        整个项目的一致性：防止代码分布在 Controllers、Models 等。\n    \n    当然，这个方法是基于我过去几年使用 Laravel 的一些经验和我在一些项目中的实践。这对我真的很有用，现在我甚至在一些中小型项目中使用。\n    如果你有不同的方法，我非常期待读一读。\n    更多现代化 PHP 知识，请前往 Laravel / PHP 知识社区 \n', null, null, null, '掘金', 'a7ab6ada-6a3b-11e8-8580-000c29753dbb');

-- ----------------------------
-- Table structure for `question`
-- ----------------------------
DROP TABLE IF EXISTS `question`;
CREATE TABLE `question` (
  `title` varchar(200) DEFAULT NULL,
  `Id` varchar(50) NOT NULL,
  `Content` mediumtext,
  `SupportCnt` int(11) DEFAULT '0',
  `OpposeCnt` int(11) DEFAULT '0',
  `CommentTo` varchar(50) DEFAULT NULL,
  `time` varchar(50) DEFAULT NULL COMMENT '创建时间',
  `UserId` varchar(50) DEFAULT NULL,
  `hits` int(11) NOT NULL DEFAULT '0' COMMENT '浏览量',
  `stick` int(11) NOT NULL DEFAULT '0' COMMENT '置顶',
  `comment` int(11) NOT NULL DEFAULT '0' COMMENT '回答数',
  `status` int(11) NOT NULL DEFAULT '0' COMMENT '加精',
  `accept` varchar(50) DEFAULT NULL COMMENT '采纳',
  `fid` varchar(50) DEFAULT NULL,
  `uname` varchar(50) DEFAULT NULL,
  `frompic` varchar(255) DEFAULT NULL,
  `filename` varchar(255) DEFAULT NULL,
  `filepath` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`Id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of question
-- ----------------------------
INSERT INTO `question` VALUES ('Java优秀文章 汇总', '04cd8add-3172-45ea-85f5-52ed69da38d7', '<p class=\"p1\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	面对浩瀚的网络学习资源，您是否为很难找到适合自己的学习资源而感到苦恼过？那么，您来对地方了。在这里我们帮助大家整理了一份适于轻松学习 Java 文章的清单。\r\n</p>\r\n<p class=\"p6\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"></span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">本清单依据 2016 年度受欢迎的技术点以及技术重点展开的内容整理。分为 Java 基础、 Java 性能、 Java 库和工具、Java 和云四大模块。涉及的技术包涵 Java 基础入门、Java 性能测试以及分析工具、Java Streams、Git 等。</span>\r\n</p>\r\n<p class=\"p8\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><span style=\"font-weight:700;\">关于 JAVA 基础</span></span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Java 编程入门</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/java/intro-to-java-course/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/java/intro-to-java-course/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：这是一个由 23 个单元构成的系列教程，它们之间相互独立。通过学习（包括视频和测验）之后，您首先可以掌握 Java 平台上的面向对象编程基础知识，随后逐步掌握您开发真实的复杂 Java 应用程序所需的更复杂的语法和库。最后，便可以使用 Java 语言和平台正常地执行面向对象编程和实际应用程序开发。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><br />\r\n</span>\r\n</p>\r\n<p class=\"p8\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><span style=\"font-weight:700;\">关于 JAVA 性能</span></span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Java&nbsp;性能测试的四项原则</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-java-performance-testing/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/java/j-lo-java-performance-testing/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：绝大数的开发人员在日常工作过程中都或多或少的遇见过性能问题。并且在软件开发前期以及开发过程中性能测试的考量是必要的，那么具备相应理论知识和实践方法也是一个优秀工程师所应当具备的素养。本文概括了四项原则，这些原则可以帮助开发人员丰富、充实测试理论，系统的开展性能测试工作，从而获得更有价值的结果。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Java&nbsp;应用性能调优实践</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-performance-tuning-practice/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/java/j-lo-performance-tuning-practice/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：Java 应用性能优化是一个老生常谈的话题。性能调优同样遵循 2-8 原则，80% 的性能问题是由 20% 的代码产生的，因此优化关键代码事半功倍。本文通过 Java 性能优化的 4 个层级：应用层、数据库层、框架层、JVM 层，简单介绍了 Java 性能诊断工具和思路，并结合搜狗商业平台的性能优化案例进行了简单的分析。可以带给您一个初步的了解。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Java&nbsp;性能分析工具</span><span class=\"s1\">（<a href=\"https://www.ibm.com/developerworks/cn/views/global/libraryview.jsp?sort_by=&amp;show_abstract=true&amp;show_all=&amp;search_flag=&amp;contentarea_by=Java+technology&amp;search_by=java+%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7&amp;topic_by=-1&amp;type_by=%E6%89%80%E6%9C%258\" target=\"_blank\">https://www.ibm.com/developerworks/cn/views/global/libraryview.jsp?sort_by=&amp;show_abstract=true&amp;show_all=&amp;search_flag=&amp;contentarea_by=Java+technology&amp;search_by=java+%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7&amp;topic_by=-1&amp;type_by=%E6%89%80%E6%9C%8</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：在解决程序性能问题之前，性能分析人员需要了解应用程序内部的运行状况以及应用运行环境的状况，并且想要以一种可视化的方式更加直接的展现出来。因此需要配合使用操作系统中集成的程序监控工具（Perfmon、vmstat、iostat 等）和 Java 中内置的监控分析工具（jcmd、jconsole、jvisualvm 等）来进行 Java 程序的性能分析。本系列文章共三篇，分别介绍这几类工具。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><br />\r\n</span>\r\n</p>\r\n<p class=\"p8\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><span style=\"font-weight:700;\">关于 JAVA 库和工具</span></span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Java Streams 系列</span><span class=\"s1\">（<img src=\"http://www.ibm.com/developerworks/cn/views/java/libraryview.jsp?sort_by=&amp;show_abstract=true&amp;show_all=&amp;search_flag=&amp;contentarea_by=Java+technology&amp;search_by=Java+Streams+%E9%83%A8%E5%88%86&amp;topic_by=-1&amp;type_by=%E6%89%80%E6%9C%89%E7%B1%BB%E5%88%AB&amp;ibm-search=\" alt=\"\" />）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：这是一个分 5 部分探索 Java SE 8 中引入的 Java Streams 库的系列文章。前两篇探讨了如何使用该库，第三篇文章探索了 Streams 实现的工作原理，后两篇介绍了如何使用 Streams 库实现并执行。通过学习，您会了解到拉姆达表达式的强大功能。您可以简明地、声明性地表达集合、数组和其他数据源上可能的并行批量操作。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">Git 分支管理最佳实践</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-git-mange/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/java/j-lo-git-mange/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：Git 是目前最流行的源代码管理工具。熟悉使用 Git 已经成为开发人员的必修课之一。对于团队开发来说，如何有效的使用 Git 的分支是一个重要的课题。需要在新功能开发、新版本发布和已有版本的维护等需求中达到一个良好的平衡。另外还需要与持续集成服务有良好的集成。本文对几种主流的 Git 分支管理实践进行了介绍，可以帮助开发团队选择自己最合适的方案。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">在 Java 应用程序中使用 Elasticsearch</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/java/j-use-elasticsearch-java-apps/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/java/j-use-elasticsearch-java-apps/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：Elasticsearch 通过将一个易于使用的 REST API 与自动化的集群扩展相结合，在全文搜索领域引起了巨大的轰动。本文详细介绍了如何从命令行和在 Java 应用程序中使用 Elasticsearch。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><br />\r\n</span>\r\n</p>\r\n<p class=\"p8\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\"><span style=\"font-weight:700;\">关于 JAVA 和云</span></span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">将 Java 应用程序扩展到移动领域和云</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/mobile/mo-extending-java-apps-mobile-cloud-trs/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/mobile/mo-extending-java-apps-mobile-cloud-trs/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：假设，您已经开始着手扩展现有的 Java 应用程序和旧有数据源，并连接到云中新的或现有的移动应用程序的工作。因此，您需要继续改进您的工作，利用最新的云和移动开发工具、平台和最佳实践来现代化您的应用程序。本文将基于 Java 的现有企业事务系统和记录系统扩展至部署到云环境中的移动应用程序的技巧、考虑因素、最佳实践和优势。</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s5\">使用 Bluemix 将 Java 应用程序迁移到混合云</span><span class=\"s1\">（<a href=\"http://www.ibm.com/developerworks/cn/cloud/library/cl-move-java-app-hybrid-cloud4-bluemix-trs/index.html\" target=\"_blank\">http://www.ibm.com/developerworks/cn/cloud/library/cl-move-java-app-hybrid-cloud4-bluemix-trs/index.html</a>）</span>\r\n</p>\r\n<p class=\"p7\" style=\"font-size:16px;color:#4F4F4F;text-align:justify;font-family:&quot;background-color:#FFFFFF;\">\r\n	<span class=\"s1\">入选原因：您对\"在云中\" 运行 Java 应用程序感兴趣？但是考虑到企业应用程序的现实，您不确定从何处开始？本系列专注于 Java 应用程序和它使用的服务，以及您如何将 Java 应用程序和关系数据库层迁移到基于 Cloud Foundry 的平台。还会介绍将服务留在内部的场景，以及在迁移到云时，可能需要针对会话管理、扩展和日志记录而执行的应用程序更改。</span>\r\n</p>', '0', '0', null, '2018-06-07 15:30:48', '9d2478de-32fa-40f2-9c97-0733265d5ea2', '3', '1', '0', '1', null, '478f5098-87fa-4278-ab29-a9afa1682ea3', 'LuMeng', 'http://192.168.202.200/group1/M00/00/00/wKjKyFsOVl-AaVoHAAAncuMFXR8111.jpg', '', '');
INSERT INTO `question` VALUES ('Java 中最大的数据结构：LinkedHashMap 了解一下？', '301ba5a0-7a33-4a85-92a3-9313e3d3635e', '<div class=\"article-content\">\r\n	<h2 class=\"heading\">\r\n		前言\r\n	</h2>\r\n	<p>\r\n		Map 家族数量众多，其中 HashMap 和 ConcurrentHashMap 用的最多，而 LinkedHashMap 似乎则是不怎么用的，但是他却有着顺序。两种，一种是添加顺序，一种是访问顺序。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		详情\r\n	</h2>\r\n	<p>\r\n		LinkedHashMap 继承了 HashMap。那么如果是你，你怎么实现这两个顺序呢？\r\n	</p>\r\n	<p>\r\n		如果实现添加顺序的话，我们可以在该类中，增加一个链表，每个节点对应 hash 表中的桶。这样，循环遍历的时候，就可以按照链表遍历了。只是会增大内存消耗。\r\n	</p>\r\n	<p>\r\n		如果实现访问顺序的话，同样也可以使用链表，但每次读取数据时，都需要更新一下链表，将最近一次读取的放到链尾。这样也就能够实现。此时也可以跟进这个特性实现 LRU（Least Recently Used） 缓存。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		如何使用？\r\n	</h2>\r\n	<p>\r\n		下面是个小 demo\r\n	</p>\r\n<pre>LinkedHashMap&lt;Integer, Integer&gt; map = <span class=\"hljs-keyword\">new</span> LinkedHashMap&lt;&gt;(<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">0.75f</span>, <span class=\"hljs-keyword\">true</span>); <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">10</span>; i++) {\r\n  map.put(i, i);\r\n} <span class=\"hljs-keyword\">for</span> (Map.Entry entry : map.entrySet()) {\r\n  System.out.println(entry.getKey() + <span class=\"hljs-string\">\":\"</span> + entry.getValue());\r\n}\r\nmap.get(<span class=\"hljs-number\">3</span>);\r\nSystem.out.println(); <span class=\"hljs-keyword\">for</span> (Map.Entry entry : map.entrySet()) {\r\n  System.out.println(entry.getKey() + <span class=\"hljs-string\">\":\"</span> + entry.getValue());\r\n}</pre>\r\n	<p>\r\n		打印结果：\r\n	</p>\r\n<pre><span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">0</span> <span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">2</span> <span class=\"hljs-number\">3</span>:<span class=\"hljs-number\">3</span> <span class=\"hljs-number\">4</span>:<span class=\"hljs-number\">4</span> <span class=\"hljs-number\">5</span>:<span class=\"hljs-number\">5</span> <span class=\"hljs-number\">6</span>:<span class=\"hljs-number\">6</span> <span class=\"hljs-number\">7</span>:<span class=\"hljs-number\">7</span> <span class=\"hljs-number\">8</span>:<span class=\"hljs-number\">8</span> <span class=\"hljs-number\">9</span>:<span class=\"hljs-number\">9</span> <span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">0</span> <span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">2</span> <span class=\"hljs-number\">4</span>:<span class=\"hljs-number\">4</span> <span class=\"hljs-number\">5</span>:<span class=\"hljs-number\">5</span> <span class=\"hljs-number\">6</span>:<span class=\"hljs-number\">6</span> <span class=\"hljs-number\">7</span>:<span class=\"hljs-number\">7</span> <span class=\"hljs-number\">8</span>:<span class=\"hljs-number\">8</span> <span class=\"hljs-number\">9</span>:<span class=\"hljs-number\">9</span> <span class=\"hljs-number\">3</span>:<span class=\"hljs-number\">3</span> </pre>\r\n	<p>\r\n		首先构造方法是有意思的，比  HashMap 多了一个 accessOrder boolean 参数。表示，按照访问顺序来排序。最新访问的放在链表尾部。\r\n	</p>\r\n	<p>\r\n		如果是默认的，则是按照添加顺序，即 accessOrder 默认是 false。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		源码实现\r\n	</h2>\r\n	<p>\r\n		如果看 LinkedHashMap 内部源码，会发现，内部确实维护了一个链表：\r\n	</p>\r\n<pre><span class=\"hljs-comment\">/**\r\n     * 双向链表的头，最久访问的\r\n     */</span> <span class=\"hljs-keyword\">transient</span> LinkedHashMap.Entry&lt;K,V&gt; head; <span class=\"hljs-comment\">/**\r\n     * 双向链表的尾，最新访问的\r\n     */</span> <span class=\"hljs-keyword\">transient</span> LinkedHashMap.Entry&lt;K,V&gt; tail;</pre>\r\n	<p>\r\n		而这个 LinkedHashMap.Entry 内部也维护了双向链表必须的元素，before，after：\r\n	</p>\r\n<pre><span class=\"hljs-comment\">/**\r\n     * HashMap.Node subclass for normal LinkedHashMap entries.\r\n     */</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Entry</span>&lt;<span class=\"hljs-title\">K</span>,<span class=\"hljs-title\">V</span>&gt; <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">HashMap</span>.<span class=\"hljs-title\">Node</span>&lt;<span class=\"hljs-title\">K</span>,<span class=\"hljs-title\">V</span>&gt; </span>{\r\n        Entry&lt;K,V&gt; before, after;\r\n        Entry(<span class=\"hljs-keyword\">int</span> hash, K key, V value, Node&lt;K,V&gt; next) { <span class=\"hljs-keyword\">super</span>(hash, key, value, next);\r\n        }\r\n    }</pre>\r\n	<p>\r\n		在添加元素的时候，会追加到尾部。\r\n	</p>\r\n<pre><span class=\"hljs-function\">Node&lt;K,V&gt; <span class=\"hljs-title\">newNode</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> hash, K key, V value, Node&lt;K,V&gt; e)</span> </span>{\r\n        LinkedHashMap.Entry&lt;K,V&gt; p = <span class=\"hljs-keyword\">new</span> LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e);\r\n        linkNodeLast(p); <span class=\"hljs-keyword\">return</span> p;\r\n    } <span class=\"hljs-comment\">// link at the end of list</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">linkNodeLast</span><span class=\"hljs-params\">(LinkedHashMap.Entry&lt;K,V&gt; p)</span> </span>{\r\n        LinkedHashMap.Entry&lt;K,V&gt; last = tail;\r\n        tail = p; <span class=\"hljs-keyword\">if</span> (last == <span class=\"hljs-keyword\">null</span>)\r\n            head = p; <span class=\"hljs-keyword\">else</span> {\r\n            p.before = last;\r\n            last.after = p;\r\n        }\r\n    }</pre>\r\n	<p>\r\n		在 get 的时候，会根据 accessOrder 属性，修改链表顺序：\r\n	</p>\r\n<pre><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> V <span class=\"hljs-title\">get</span><span class=\"hljs-params\">(Object key)</span> </span>{\r\n        Node&lt;K,V&gt; e; <span class=\"hljs-keyword\">if</span> ((e = getNode(hash(key), key)) == <span class=\"hljs-keyword\">null</span>) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">null</span>; <span class=\"hljs-keyword\">if</span> (accessOrder)\r\n            afterNodeAccess(e); <span class=\"hljs-keyword\">return</span> e.value;\r\n    } <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">afterNodeAccess</span><span class=\"hljs-params\">(Node&lt;K,V&gt; e)</span> </span>{ <span class=\"hljs-comment\">// move node to last</span> LinkedHashMap.Entry&lt;K,V&gt; last; <span class=\"hljs-keyword\">if</span> (accessOrder &amp;&amp; (last = tail) != e) {\r\n            LinkedHashMap.Entry&lt;K,V&gt; p =\r\n                (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;\r\n            p.after = <span class=\"hljs-keyword\">null</span>; <span class=\"hljs-keyword\">if</span> (b == <span class=\"hljs-keyword\">null</span>)\r\n                head = a; <span class=\"hljs-keyword\">else</span> b.after = a; <span class=\"hljs-keyword\">if</span> (a != <span class=\"hljs-keyword\">null</span>)\r\n                a.before = b; <span class=\"hljs-keyword\">else</span> last = b; <span class=\"hljs-keyword\">if</span> (last == <span class=\"hljs-keyword\">null</span>)\r\n                head = p; <span class=\"hljs-keyword\">else</span> {\r\n                p.before = last;\r\n                last.after = p;\r\n            }\r\n            tail = p;\r\n            ++modCount;\r\n        }\r\n    }</pre>\r\n	<p>\r\n		同时注意：这里修改了 modCount，即使是读操作，并发也是不安全的。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		如何实现  LRU 缓存？\r\n	</h2>\r\n	<p>\r\n		LRU 缓存：LRU（Least Recently Used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。\r\n	</p>\r\n	<p>\r\n		LinkedHashMap 并没有帮我我们实现具体，需要我们自己实现 。具体实现方法是 removeEldestEntry 方法。\r\n	</p>\r\n	<p>\r\n		一起来看看原理。\r\n	</p>\r\n	<p>\r\n		首先，HashMap 在 putVal 方法最后，会调用 afterNodeInsertion 方法，其实就是留给 LinkedHashMap 的。而 LinkedHashMap 的具体实现则是根据一些条件，判断是否需要删除 head 节点。\r\n	</p>\r\n	<p>\r\n		源码如下：\r\n	</p>\r\n<pre><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">afterNodeInsertion</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">boolean</span> evict)</span> </span>{ <span class=\"hljs-comment\">// possibly remove eldest</span> LinkedHashMap.Entry&lt;K,V&gt; first; <span class=\"hljs-keyword\">if</span> (evict &amp;&amp; (first = head) != <span class=\"hljs-keyword\">null</span> &amp;&amp; removeEldestEntry(first)) {\r\n            K key = first.key;\r\n            removeNode(hash(key), key, <span class=\"hljs-keyword\">null</span>, <span class=\"hljs-keyword\">false</span>, <span class=\"hljs-keyword\">true</span>);\r\n        }\r\n    }</pre>\r\n	<p>\r\n		evict 参数表示是否需要删除某个元素，而这个 if 判断需要满足的条件如上：head 不能是 null，调用 removeEldestEntry 方法，返回 true 的话，就删除这个 head。而这个方法默认是返回 false 的，等待着你来重写。\r\n	</p>\r\n	<p>\r\n		所以，removeEldestEntry 方法的实现通常是这样：\r\n	</p>\r\n<pre><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span>&nbsp;<span class=\"hljs-keyword\">boolean</span>&nbsp;<span class=\"hljs-title\">removeEldestEntry</span><span class=\"hljs-params\">(Map.Entry&lt;K,&nbsp;V&gt;&nbsp;eldest)</span></span>{&nbsp;&nbsp;&nbsp;&nbsp;\r\n&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;size() &gt; capacity;&nbsp;&nbsp;\r\n}&nbsp;</pre>\r\n	<p>\r\n		如果长度大于容量了，那么就需要清除不经常访问的缓存了。afterNodeInsertion 会调用 removeNode 方法，删除掉 head 节点 —— 如果 accessOrder 是 true 的话，这个节点就是最不经常访问的节点。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		拾遗\r\n	</h2>\r\n	<p>\r\n		LinkedHashMap 重写了一些 HashMap 的方法，例如 containsValue 方法，这个方法大家猜一猜，怎么重写比较合理？\r\n	</p>\r\n	<p>\r\n		HashMap 使用了双重循环，先循环外层的 hash 表，再循环内层的 entry 链表。性能可想而知。\r\n	</p>\r\n	<p>\r\n		但 LinkedHashMap 内部有个元素链表，直接遍历链表就行。相对而言而高很多。\r\n	</p>\r\n<pre><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">boolean</span> <span class=\"hljs-title\">containsValue</span><span class=\"hljs-params\">(Object value)</span> </span>{ <span class=\"hljs-keyword\">for</span> (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != <span class=\"hljs-keyword\">null</span>; e = e.after) {\r\n            V v = e.value; <span class=\"hljs-keyword\">if</span> (v == value || (value != <span class=\"hljs-keyword\">null</span> &amp;&amp; value.equals(v))) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">true</span>;\r\n        } <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">false</span>;\r\n    }</pre>\r\n	<p>\r\n		这也算一种空间换时间的策略吧。\r\n	</p>\r\n	<p>\r\n		get 方法当然也是要重写的。因为需要根据 accessOrder 更新链表。\r\n	</p>\r\n	<h2 class=\"heading\">\r\n		总结\r\n	</h2>\r\n	<p>\r\n		雪薇的总结的一下：\r\n	</p>\r\n	<p>\r\n		LinkedHashMap 内部包含一个双向链表维护顺序，支持两种顺序——添加顺序，访问顺序。\r\n	</p>\r\n	<p>\r\n		默认就是按照添加顺序来的，如果要改成访问顺序的话，构造方法中的 accessOrder 需要设置成 true。这样，每次调用  get 方法，就会将刚刚访问的元素更新到链表尾部。\r\n	</p>\r\n	<p>\r\n		关于 LRU，在accessOrder 为 true 的模式下，你可以重写 removeEldestEntry 方法，返回size() &gt; capacity，这样，就可以删除最不常访问的元素。\r\n	</p>\r\n</div>\r\n<br />', '0', '0', null, '2018-05-26 15:39:02', '2ddc30b3-deeb-46ad-b660-5597f0b93c06', '13', '1', '0', '0', null, '2d869735-4eeb-4093-aba3-6442840a59af', 'LM', 'http://192.168.202.200/group1/M00/00/00/wKjKyFsYmCaAKZaNABKozpUGDmM890.jpg', 'java资源', 'http://192.168.202.200/group1/M00/00/00/wKjKyFsJDxWASIA8AAAAAAAAAAA6446884');
INSERT INTO `question` VALUES ('C++与我同在', 'b512be6a-23cf-42b6-a9a8-0bb5d2d50fb0', '<p>\r\n	<span style=\"background-color:#E53333;\">在下要介绍的这位博主的主页</span>是<a href=\"http://www.jellythink.com/\" target=\"_blank\">http://www.jellythink.com/</a>。\r\n</p>\r\n<p>\r\n	声明，我绝不是托。。。只是在这位博主的指引下，学习到了很多的知识，并有感于博主的知识渊博，所以写下这篇文章。\r\n</p>\r\n<p>\r\n	这们博主的文章条理清楚，如果是程序老鸟，可以从中发现更新的知识点；如果是新手，那更是让人觉得浅显易懂。\r\n</p>\r\n<p>\r\n	这位博主除了有c++的文章，在下还觉得他的lua文章也是值得去仔细品味一番的。\r\n</p>\r\n<p>\r\n	对于lua文章，我就不说了，因为是一个系列，所以一直往下看就可以。\r\n</p>\r\n<p>\r\n	而对于c++文章，因为其中有一些文章不在我的学习范围里，并没有去学习。\r\n</p>\r\n<p>\r\n	余下我看过的文章，都觉得十分的精辟。以下推荐几篇：\r\n</p>\r\n<p>\r\n	<a href=\"http://www.jellythink.com/archives/205\" target=\"_blank\">http://www.jellythink.com/archives/205</a>&nbsp;----》static_cast、dynamic_cast、const_cast和reinterpret_cast总结\r\n</p>\r\n<p>\r\n	<a href=\"http://www.jellythink.com/archives/378\" target=\"_blank\">http://www.jellythink.com/archives/378</a>&nbsp;----》C++中复制构造函数与重载赋值操作符总结\r\n</p>\r\n<p>\r\n	<a href=\"http://www.jellythink.com/archives/773\" target=\"_blank\">http://www.jellythink.com/archives/773</a>&nbsp;----》C++11中的std::bind\r\n</p>\r\n<p>\r\n	<a href=\"http://www.jellythink.com/archives/771\" target=\"_blank\">http://www.jellythink.com/archives/771</a>&nbsp;----》C++11中的std::function\r\n</p>\r\n<p>\r\n	<a href=\"http://www.jellythink.com/archives/668\" target=\"_blank\">http://www.jellythink.com/archives/668</a> ----》C++中的Lambda表达式\r\n</p>\r\n<p>\r\n	最后一篇：\r\n</p>\r\n<a href=\"http://www.jellythink.com/archives/413\" target=\"_blank\">http://www.jellythink.com/archives/413</a>&nbsp;----》C、C++内存对齐<span style=\"background-color:#E53333;\"></span>', '0', '0', null, '2018-06-07 15:15:52', '99ef5612-f650-460d-9b0f-13c81f8e5cb2', '4', '0', '0', '0', null, '6ddee1d8-8957-41c7-8554-21a0104c7690', 'LL', null, '', 'http://192.168.202.200/group1/M00/00/00/wKjKyFsY25yAULSmAAAAAAAAAAA9904130');
INSERT INTO `question` VALUES ('《我的大学生活感悟》', 'fa9ab261-fc96-4a67-9af3-7fc166bd78e2', '<p>\r\n	&nbsp; <img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/116.gif\" alt=\"\" border=\"0\" />\r\n</p>\r\n<p>\r\n	&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"background-color:#E53333;\">大学</span><span style=\"background-color:#E53333;\"></span>，是梦开始的地方；为了不使这个梦在毕业时落空：那我们就要用一种认终为始的心态去规划与度过大学生活。大学也是我们人生中最集中的能够扬长避短的时期，早能够尽情折腾的时期，所以如果谁的大学默默无闻了，平平淡淡了，那他就没有真正的理解大学的含义与作用。因为一旦失去青春的激情，便永远也找不到了，所以大学必须要且行且惜！\r\n</p>\r\n<p>\r\n	&emsp;&emsp;大一是大学的开端，是影响大学其他三年的重要一年，所以这进入大学的第一步要走好，这样才能够为其他的三年打下基础，我时刻坚信只要做到了步步为营，就能步步升高，就能步步为赢。一切只因“当梦想扬帆起航！\r\n</p>\r\n<p>\r\n	&emsp;&emsp;不如大学，是我们人生的另一个新起点，是真正好处的大学，是每个幸运的大学生生命中最重要的旅程，这一路由三个宽阔的台阶和无数的细砖碎瓦组成我们年轻的凛冽和青春岁月！然而，该怎样应对大学的第一个台阶。大一是此刻每个刚进入大学的同学所思考的，所怅惘的。\r\n</p>\r\n<p>\r\n	&emsp;&emsp;大一，是开始的良端，也是完结的预兆。大一和我们的许多境遇一样，只有一次，而这个开始是有着制胜的影响甚至决定好处！<span>[由www.duanmeiwen.com整理]</span>\r\n</p>\r\n<p>\r\n	&emsp;&emsp;大学和中学有着本质的区别，在那里，你会发现，你更自由了，更有主宰权了，完全掌控着自己的生活！也因为如此，我们更容易迷茫，更容易失去方向，有时候都不明白自己到底追求的是什么？\r\n</p>\r\n<p>\r\n	&emsp;&emsp;人生目标是人生道路的航标，是人生前进的动力。在自我迷失一段时间以后，我透过与高年级同学的交流以及与老师的沟通，初步确立了我的大学奋斗目标：全面发展。我决定透过大学三年的学习成为思想觉悟高，心理素质好，专业技术精，工作潜力强的复合型人才。这也是新世纪对大学生的要求。\r\n</p>\r\n<p>\r\n	&emsp;&emsp;确立了目标，我们学生重新获得了源源不断的动力。因为对英语很感兴趣，我便以英语为突破口，为提高英语口语潜力，我改掉了睡懒觉的坏习惯，每一天早上在校园里大声地朗诵英语，用”疯狂“英语问候校园的一草一木。透过努力，学习成绩开始逐步提高。\r\n</p>\r\n<p>\r\n	&emsp;&emsp;大学生活是漫漫人生路的一个阶段，也是人生之歌的一个乐章。这段路即使短暂的，也是漫长的，这个乐章既可能是优美动听的，也可能是遗憾苦涩的。虽然，我的大学生活才刚刚开始，但我相信它会是充满快乐的。\r\n</p>\r\n<p>\r\n	&emsp;&emsp;最后，我在那里拜祝大家共同努力，共同进步，多多积累经验，让自己能走好以后的路。<img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/85.gif\" alt=\"\" border=\"0\" /><img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/85.gif\" alt=\"\" border=\"0\" /><img src=\"http://localhost:8080/resources/kindeditor/plugins/emoticons/images/85.gif\" alt=\"\" border=\"0\" />\r\n</p>', '0', '0', null, '2018-06-06 19:19:48', 'f3d951ec-d6e1-453a-8a61-0129fe597660', '7', '0', '0', '0', null, '39c84611-d107-4da0-964a-7183cc5e1024', 'LLuMM', null, '', '');

-- ----------------------------
-- Table structure for `sysconf`
-- ----------------------------
DROP TABLE IF EXISTS `sysconf`;
CREATE TABLE `sysconf` (
  `id` varchar(50) NOT NULL,
  `value` varchar(200) NOT NULL,
  `key` varchar(50) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of sysconf
-- ----------------------------
INSERT INTO `sysconf` VALUES ('8223baeb-a7e9-4932-a64b-d709300473e2', '2.0', 'version');
INSERT INTO `sysconf` VALUES ('c0b07303-6e23-4f89-9570-d6aef0d7b92f', '4305', 'download');

-- ----------------------------
-- Table structure for `tb_user`
-- ----------------------------
DROP TABLE IF EXISTS `tb_user`;
CREATE TABLE `tb_user` (
  `uid` varchar(50) NOT NULL,
  `username` varchar(20) NOT NULL,
  `password` varchar(50) NOT NULL,
  `email` varchar(20) DEFAULT NULL,
  `post` int(11) DEFAULT NULL,
  `sign` varchar(20) DEFAULT NULL,
  `face` varchar(255) DEFAULT NULL,
  `joindate` varchar(50) DEFAULT NULL,
  `lastlogin` varchar(50) DEFAULT NULL,
  `isbest` int(11) DEFAULT NULL,
  `userfav` varchar(255) DEFAULT NULL,
  `userinfo` varchar(255) DEFAULT NULL,
  `userhidden` int(11) DEFAULT NULL,
  `userviews` int(11) DEFAULT NULL,
  `privilege` int(11) DEFAULT NULL,
  `visits` int(11) DEFAULT '0',
  `status` int(11) DEFAULT '0',
  `phone` varchar(50) DEFAULT NULL,
  `city` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`uid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_user
-- ----------------------------
INSERT INTO `tb_user` VALUES ('2abe95d2-fa87-4af0-8e3b-b1ca70b9e7b7', 'admin', 'ISMvKXpXpadDiUoOSoAfww==', '1137770978@qq.com', null, null, null, '2018-05-15 13:27:44', '2018-06-07 17:43:37', null, null, null, null, null, '0', '44', '1', '15754334355', null);
INSERT INTO `tb_user` VALUES ('2ddc30b3-deeb-46ad-b660-5597f0b93c06', 'LM', 'ICy5YqxZB1uWSwcVLSNLcA==', '1137770978@qq.com', null, '做自己！', 'http://192.168.202.200/group1/M00/00/00/wKjKyFsYmCaAKZaNABKozpUGDmM890.jpg', '2018-04-20 15:31:19', '2018-06-07 17:56:57', null, null, null, null, null, '1', '44', '1', null, '重庆');
INSERT INTO `tb_user` VALUES ('99ef5612-f650-460d-9b0f-13c81f8e5cb2', 'LL', 'ICy5YqxZB1uWSwcVLSNLcA==', '1137770978@qq.com', null, null, null, null, '2018-06-07 16:43:32', null, null, null, null, null, '1', '44', '0', null, null);
INSERT INTO `tb_user` VALUES ('9d2478de-32fa-40f2-9c97-0733265d5ea2', 'LuMeng', 'RvlMjeFPs2aAhQdo/xt/Kg==', '1137770978@qq.com', null, null, 'http://192.168.202.200/group1/M00/00/00/wKjKyFsOVl-AaVoHAAAncuMFXR8111.jpg', '2018-05-30 15:31:19', '2018-06-07 15:59:52', null, null, null, null, null, '0', '44', '0', null, null);
INSERT INTO `tb_user` VALUES ('cd2e66c1-fe69-4844-92ff-38ecbfb88e0b', 'MM', 'ICy5YqxZB1uWSwcVLSNLcA==', null, null, null, null, null, '2018-06-06 21:08:10', null, null, null, null, null, '1', '44', '0', null, null);
INSERT INTO `tb_user` VALUES ('f3d951ec-d6e1-453a-8a61-0129fe597660', 'LLuMM', 'RvlMjeFPs2aAhQdo/xt/Kg==', '11@qq.com', null, '生命不息，学习不止！', null, '2018-06-06 19:16:46', '2018-06-07 16:10:29', null, null, null, null, null, null, '44', '0', null, '长春');

-- ----------------------------
-- Table structure for `updatelog`
-- ----------------------------
DROP TABLE IF EXISTS `updatelog`;
CREATE TABLE `updatelog` (
  `id` varchar(50) NOT NULL,
  `description` varchar(1000) NOT NULL,
  `version` varchar(20) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of updatelog
-- ----------------------------
